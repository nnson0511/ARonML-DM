{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyodbc\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = '192.168.1.212'\n",
    "database = 'master'\n",
    "username = 'test'\n",
    "password = 'tester2024'\n",
    "\n",
    "mssql_conn_str = f'DRIVER={{SQL Server}};SERVER={server};DATABASE={database};UID={username};PWD={password};'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        select cp.CompanyId, CompanyAge, CompanyType, FDI, CapitalAmount, NumberOfLabors, Region, Status,\n",
      "                [2015_11], [2015_12], [2015_13], [2015_14], [2015_15], [2015_16], [2015_17], [2015_18], [2015_19], [2015_20], [2015_21], [2015_22], [2015_23], [2015_24],\n",
      "                [2016_11], [2016_12], [2016_13], [2016_14], [2016_15], [2016_16], [2016_17], [2016_18], [2016_19], [2016_20], [2016_21], [2016_22], [2016_23], [2016_24],\n",
      "                [2017_11], [2017_12], [2017_13], [2017_14], [2017_15], [2017_16], [2017_17], [2017_18], [2017_19], [2017_20], [2017_21], [2017_22], [2017_23], [2017_24],\n",
      "                [2018_11], [2018_12], [2018_13], [2018_14], [2018_15], [2018_16], [2018_17], [2018_18], [2018_19], [2018_20], [2018_21], [2018_22], [2018_23], [2018_24],\n",
      "                [2019_11], [2019_12], [2019_13], [2019_14], [2019_15], [2019_16], [2019_17], [2019_18], [2019_19], [2019_20], [2019_21], [2019_22], [2019_23], [2019_24],\n",
      "                [2020_11], [2020_12], [2020_13], [2020_14], [2020_15], [2020_16], [2020_17], [2020_18], [2020_19], [2020_20], [2020_21], [2020_22], [2020_23], [2020_24],\n",
      "                [2021_11], [2021_12], [2021_13], [2021_14], [2021_15], [2021_16], [2021_17], [2021_18], [2021_19], [2021_20], [2021_21], [2021_22], [2021_23], [2021_24],\n",
      "                [2022_11], [2022_12], [2022_13], [2022_14], [2022_15], [2022_16], [2022_17], [2022_18], [2022_19], [2022_20], [2022_21], [2022_22], [2022_23], [2022_24]\n",
      "        from ProjectNew..CompanyProfile cp\n",
      "        join ProjectNew..FinancialValue2 fv on cp.CompanyId = fv.CompanyId\n",
      "        where CompanyAge > 9\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "msql_query = f\"\"\"\n",
    "        select cp.CompanyId, CompanyAge, CompanyType, FDI, CapitalAmount, NumberOfLabors, Region, Status,\n",
    "                [2015_11], [2015_12], [2015_13], [2015_14], [2015_15], [2015_16], [2015_17], [2015_18], [2015_19], [2015_20], [2015_21], [2015_22], [2015_23], [2015_24],\n",
    "                [2016_11], [2016_12], [2016_13], [2016_14], [2016_15], [2016_16], [2016_17], [2016_18], [2016_19], [2016_20], [2016_21], [2016_22], [2016_23], [2016_24],\n",
    "                [2017_11], [2017_12], [2017_13], [2017_14], [2017_15], [2017_16], [2017_17], [2017_18], [2017_19], [2017_20], [2017_21], [2017_22], [2017_23], [2017_24],\n",
    "                [2018_11], [2018_12], [2018_13], [2018_14], [2018_15], [2018_16], [2018_17], [2018_18], [2018_19], [2018_20], [2018_21], [2018_22], [2018_23], [2018_24],\n",
    "                [2019_11], [2019_12], [2019_13], [2019_14], [2019_15], [2019_16], [2019_17], [2019_18], [2019_19], [2019_20], [2019_21], [2019_22], [2019_23], [2019_24],\n",
    "                [2020_11], [2020_12], [2020_13], [2020_14], [2020_15], [2020_16], [2020_17], [2020_18], [2020_19], [2020_20], [2020_21], [2020_22], [2020_23], [2020_24],\n",
    "                [2021_11], [2021_12], [2021_13], [2021_14], [2021_15], [2021_16], [2021_17], [2021_18], [2021_19], [2021_20], [2021_21], [2021_22], [2021_23], [2021_24],\n",
    "                [2022_11], [2022_12], [2022_13], [2022_14], [2022_15], [2022_16], [2022_17], [2022_18], [2022_19], [2022_20], [2022_21], [2022_22], [2022_23], [2022_24]\n",
    "        from ProjectNew..CompanyProfile cp\n",
    "        join ProjectNew..FinancialValue2 fv on cp.CompanyId = fv.CompanyId\n",
    "        where CompanyAge > 9\n",
    "        \"\"\"\n",
    "print(msql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kết nối cơ sở dữ liệu thành công\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\2\\ipykernel_10116\\1879818091.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data = pd.read_sql_query(msql_query, mssql_conn)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    mssql_conn = pyodbc.connect(mssql_conn_str)\n",
    "    print(\"Kết nối cơ sở dữ liệu thành công\")\n",
    "except pyodbc.Error as e:\n",
    "    print(f\"Lỗi khi kết nối cơ sở dữ liệu: {e}\")\n",
    "\n",
    "data = pd.read_sql_query(msql_query, mssql_conn)\n",
    "\n",
    "mssql_conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_data(df1, n):\n",
    "    df = df1.copy()\n",
    "\n",
    "    # One-hot encoding cho cột CompanyType\n",
    "    df = pd.get_dummies(df, columns=['CompanyType'], prefix='Type')\n",
    "        \n",
    "    if 'CompanyId' in df.columns:\n",
    "        df.drop(columns=['CompanyId'], inplace=True)\n",
    "\n",
    "    # Duplicate các dòng dữ liệu có status = 1 n lần\n",
    "    if n > 1:\n",
    "        df_status_1 = df[df['status'] == 1]\n",
    "        df = pd.concat([df] + [df_status_1] * (n - 1), ignore_index=True)\n",
    "\n",
    "    # Normalize các cột còn lại với giá trị từ 0 đến 1\n",
    "    scaler = MinMaxScaler()\n",
    "    df[df.columns] = scaler.fit_transform(df[df.columns])\n",
    "    \n",
    "    # Thay thế tất cả các giá trị NaN trong df thành 0\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = processing_data(data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CompanyAge</th>\n",
       "      <th>FDI</th>\n",
       "      <th>CapitalAmount</th>\n",
       "      <th>NumberOfLabors</th>\n",
       "      <th>Region</th>\n",
       "      <th>Status</th>\n",
       "      <th>2015_11</th>\n",
       "      <th>2015_12</th>\n",
       "      <th>2015_13</th>\n",
       "      <th>2015_14</th>\n",
       "      <th>...</th>\n",
       "      <th>2022_19</th>\n",
       "      <th>2022_20</th>\n",
       "      <th>2022_21</th>\n",
       "      <th>2022_22</th>\n",
       "      <th>2022_23</th>\n",
       "      <th>2022_24</th>\n",
       "      <th>Type_LLC1</th>\n",
       "      <th>Type_LLC2</th>\n",
       "      <th>Type_PE</th>\n",
       "      <th>Type_SC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.004616</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.004240</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236214</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.003024</td>\n",
       "      <td>0.196133</td>\n",
       "      <td>0.332620</td>\n",
       "      <td>0.344626</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.004277</td>\n",
       "      <td>0.000811</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58896</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.004301</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236281</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.003024</td>\n",
       "      <td>0.196133</td>\n",
       "      <td>0.332620</td>\n",
       "      <td>0.344626</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58897</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>0.004758</td>\n",
       "      <td>0.001727</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58898</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000963</td>\n",
       "      <td>0.004520</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.001829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236634</td>\n",
       "      <td>0.000925</td>\n",
       "      <td>0.003149</td>\n",
       "      <td>0.196174</td>\n",
       "      <td>0.332615</td>\n",
       "      <td>0.344621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58899</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58900</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000952</td>\n",
       "      <td>0.004888</td>\n",
       "      <td>0.001638</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236281</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.003094</td>\n",
       "      <td>0.196046</td>\n",
       "      <td>0.332433</td>\n",
       "      <td>0.344429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58901 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CompanyAge  FDI  CapitalAmount  NumberOfLabors  Region  Status  \\\n",
       "0            0.28  0.0       0.000097        0.000076     1.0     0.0   \n",
       "1            0.08  0.0       0.000009        0.000031     1.0     0.0   \n",
       "2            0.28  0.0       0.000001        0.000138     0.0     0.0   \n",
       "3            0.08  0.0       0.000029        0.000076     1.0     0.0   \n",
       "4            0.44  0.0       0.000031        0.000000     1.0     1.0   \n",
       "...           ...  ...            ...             ...     ...     ...   \n",
       "58896        0.28  0.0       0.000122        0.000061     1.0     0.0   \n",
       "58897        0.32  0.0       0.000175        0.000076     0.0     0.0   \n",
       "58898        0.24  0.0       0.000374        0.000153     0.0     0.0   \n",
       "58899        0.00  0.0       0.000044        0.000153     1.0     1.0   \n",
       "58900        0.88  0.0       0.000419        0.000153     0.0     0.0   \n",
       "\n",
       "        2015_11   2015_12   2015_13   2015_14  ...   2022_19   2022_20  \\\n",
       "0      0.000467  0.004616  0.000714  0.000517  ...  0.000000  0.000000   \n",
       "1      0.000254  0.004240  0.000714  0.000000  ...  0.236214  0.000006   \n",
       "2      0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "3      0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "4      0.000290  0.004277  0.000811  0.000562  ...  0.000000  0.000000   \n",
       "...         ...       ...       ...       ...  ...       ...       ...   \n",
       "58896  0.000369  0.004301  0.001001  0.000516  ...  0.236281  0.000056   \n",
       "58897  0.000922  0.004758  0.001727  0.000620  ...  0.000000  0.000000   \n",
       "58898  0.000963  0.004520  0.001948  0.001829  ...  0.236634  0.000925   \n",
       "58899  0.000222  0.000000  0.000000  0.000512  ...  0.000000  0.000000   \n",
       "58900  0.000952  0.004888  0.001638  0.000807  ...  0.236281  0.000160   \n",
       "\n",
       "        2022_21   2022_22   2022_23   2022_24  Type_LLC1  Type_LLC2  Type_PE  \\\n",
       "0      0.000000  0.000000  0.000000  0.000000        0.0        0.0      0.0   \n",
       "1      0.003024  0.196133  0.332620  0.344626        0.0        1.0      0.0   \n",
       "2      0.000000  0.000000  0.000000  0.000000        1.0        0.0      0.0   \n",
       "3      0.000000  0.000000  0.000000  0.000000        0.0        0.0      0.0   \n",
       "4      0.000000  0.000000  0.000000  0.000000        0.0        1.0      0.0   \n",
       "...         ...       ...       ...       ...        ...        ...      ...   \n",
       "58896  0.003024  0.196133  0.332620  0.344626        0.0        0.0      0.0   \n",
       "58897  0.000000  0.000000  0.000000  0.000000        0.0        1.0      0.0   \n",
       "58898  0.003149  0.196174  0.332615  0.344621        0.0        0.0      0.0   \n",
       "58899  0.000000  0.000000  0.000000  0.000000        1.0        0.0      0.0   \n",
       "58900  0.003094  0.196046  0.332433  0.344429        0.0        1.0      0.0   \n",
       "\n",
       "       Type_SC  \n",
       "0          1.0  \n",
       "1          0.0  \n",
       "2          0.0  \n",
       "3          1.0  \n",
       "4          0.0  \n",
       "...        ...  \n",
       "58896      1.0  \n",
       "58897      0.0  \n",
       "58898      1.0  \n",
       "58899      0.0  \n",
       "58900      0.0  \n",
       "\n",
       "[58901 rows x 122 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def train_logistic_regression_kfold(processed_data, k=5):\n",
    "    df = processed_data.copy()\n",
    "    warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "    # Chia dữ liệu thành biến độc lập (X) và biến phụ thuộc (y)\n",
    "    X = df.drop('Status', axis=1)\n",
    "    y = df['Status']\n",
    "\n",
    "    # Khởi tạo mô hình Logistic Regression\n",
    "    model = LogisticRegression()\n",
    "\n",
    "    # Khởi tạo KFold\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    accuracies = []\n",
    "    reports = []\n",
    "\n",
    "    fold = 1\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        print(f\"Training on fold {fold}...\")\n",
    "        \n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Huấn luyện mô hình trên tập train\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Dự đoán trên tập test\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Đánh giá mô hình\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        reports.append(report)\n",
    "\n",
    "        print(f\"Accuracy for fold {fold}: {accuracy}\")\n",
    "        fold += 1\n",
    "\n",
    "    # Tính toán và in ra báo cáo cuối cùng\n",
    "    print(\"\\nFinal Report:\")\n",
    "    print(f\"Mean Accuracy: {np.mean(accuracies)}\")\n",
    "    print(f\"Standard Deviation of Accuracy: {np.std(accuracies)}\")\n",
    "    \n",
    "    # In ra classification report cho từng fold\n",
    "    for i, report in enumerate(reports):\n",
    "        print(f\"\\nClassification Report for fold {i+1}:\")\n",
    "        print(classification_report(y.iloc[test_index], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 1...\n",
      "Accuracy for fold 1: 0.8768355827179357\n",
      "Training on fold 2...\n",
      "Accuracy for fold 2: 0.8771646859083192\n",
      "Training on fold 3...\n",
      "Accuracy for fold 3: 0.8739388794567062\n",
      "Training on fold 4...\n",
      "Accuracy for fold 4: 0.8733446519524618\n",
      "Training on fold 5...\n",
      "Accuracy for fold 5: 0.8737691001697793\n",
      "\n",
      "Final Report:\n",
      "Mean Accuracy: 0.8750105800410404\n",
      "Standard Deviation of Accuracy: 0.0016392643269249711\n",
      "\n",
      "Classification Report for fold 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.99      0.93     10298\n",
      "         1.0       0.48      0.04      0.08      1482\n",
      "\n",
      "    accuracy                           0.87     11780\n",
      "   macro avg       0.68      0.52      0.51     11780\n",
      "weighted avg       0.83      0.87      0.82     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.99      0.93     10298\n",
      "         1.0       0.48      0.04      0.08      1482\n",
      "\n",
      "    accuracy                           0.87     11780\n",
      "   macro avg       0.68      0.52      0.51     11780\n",
      "weighted avg       0.83      0.87      0.82     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.99      0.93     10298\n",
      "         1.0       0.48      0.04      0.08      1482\n",
      "\n",
      "    accuracy                           0.87     11780\n",
      "   macro avg       0.68      0.52      0.51     11780\n",
      "weighted avg       0.83      0.87      0.82     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.99      0.93     10298\n",
      "         1.0       0.48      0.04      0.08      1482\n",
      "\n",
      "    accuracy                           0.87     11780\n",
      "   macro avg       0.68      0.52      0.51     11780\n",
      "weighted avg       0.83      0.87      0.82     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.99      0.93     10298\n",
      "         1.0       0.48      0.04      0.08      1482\n",
      "\n",
      "    accuracy                           0.87     11780\n",
      "   macro avg       0.68      0.52      0.51     11780\n",
      "weighted avg       0.83      0.87      0.82     11780\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_logistic_regression_kfold(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "def train_xgboost_kfold(processed_data, k=5):\n",
    "    df = processed_data.copy()\n",
    "    warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "    \n",
    "    # Chia dữ liệu thành biến độc lập (X) và biến phụ thuộc (y)\n",
    "    X = df.drop('Status', axis=1)\n",
    "    y = df['Status']\n",
    "\n",
    "    # Khởi tạo KFold\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    accuracies = []\n",
    "    reports = []\n",
    "\n",
    "    fold = 1\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        print(f\"Training on fold {fold}...\")\n",
    "        \n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Khởi tạo và huấn luyện mô hình XGBoost trên tập train\n",
    "        model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Dự đoán trên tập test\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Đánh giá mô hình\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "        reports.append(report)\n",
    "\n",
    "        print(f\"Accuracy for fold {fold}: {accuracy}\")\n",
    "        fold += 1\n",
    "\n",
    "    # Tính toán và in ra báo cáo cuối cùng\n",
    "    print(\"\\nFinal Report:\")\n",
    "    print(f\"Mean Accuracy: {np.mean(accuracies)}\")\n",
    "    print(f\"Standard Deviation of Accuracy: {np.std(accuracies)}\")\n",
    "    \n",
    "    # In ra classification report cho từng fold\n",
    "    for i, report in enumerate(reports):\n",
    "        print(f\"\\nClassification Report for fold {i+1}:\")\n",
    "        print(classification_report(y.iloc[test_index], y_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 1...\n",
      "Accuracy for fold 1: 0.8801459977930566\n",
      "Training on fold 2...\n",
      "Accuracy for fold 2: 0.881578947368421\n",
      "Training on fold 3...\n",
      "Accuracy for fold 3: 0.8809847198641766\n",
      "Training on fold 4...\n",
      "Accuracy for fold 4: 0.881578947368421\n",
      "Training on fold 5...\n",
      "Accuracy for fold 5: 0.882088285229202\n",
      "\n",
      "Final Report:\n",
      "Mean Accuracy: 0.8812753795246554\n",
      "Standard Deviation of Accuracy: 0.0006640946754673247\n",
      "\n",
      "Classification Report for fold 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.97      0.94     10298\n",
      "         1.0       0.57      0.25      0.34      1482\n",
      "\n",
      "    accuracy                           0.88     11780\n",
      "   macro avg       0.74      0.61      0.64     11780\n",
      "weighted avg       0.86      0.88      0.86     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.97      0.94     10298\n",
      "         1.0       0.57      0.25      0.34      1482\n",
      "\n",
      "    accuracy                           0.88     11780\n",
      "   macro avg       0.74      0.61      0.64     11780\n",
      "weighted avg       0.86      0.88      0.86     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.97      0.94     10298\n",
      "         1.0       0.57      0.25      0.34      1482\n",
      "\n",
      "    accuracy                           0.88     11780\n",
      "   macro avg       0.74      0.61      0.64     11780\n",
      "weighted avg       0.86      0.88      0.86     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.97      0.94     10298\n",
      "         1.0       0.57      0.25      0.34      1482\n",
      "\n",
      "    accuracy                           0.88     11780\n",
      "   macro avg       0.74      0.61      0.64     11780\n",
      "weighted avg       0.86      0.88      0.86     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.97      0.94     10298\n",
      "         1.0       0.57      0.25      0.34      1482\n",
      "\n",
      "    accuracy                           0.88     11780\n",
      "   macro avg       0.74      0.61      0.64     11780\n",
      "weighted avg       0.86      0.88      0.86     11780\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_xgboost_kfold(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "def train_lightgbm_kfold(processed_data, k=5):\n",
    "    df = processed_data.copy()\n",
    "    warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "    \n",
    "    # Chia dữ liệu thành biến độc lập (X) và biến phụ thuộc (y)\n",
    "    X = df.drop('Status', axis=1)\n",
    "    y = df['Status']\n",
    "\n",
    "    # Khởi tạo KFold\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    accuracies = []\n",
    "    reports = []\n",
    "\n",
    "    fold = 1\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        print(f\"Training on fold {fold}...\")\n",
    "        \n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Khởi tạo và huấn luyện mô hình LightGBM trên tập train\n",
    "        model = lgb.LGBMClassifier()\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Dự đoán trên tập test\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Đánh giá mô hình\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "        reports.append(report)\n",
    "\n",
    "        print(f\"Accuracy for fold {fold}: {accuracy}\")\n",
    "        fold += 1\n",
    "\n",
    "    # Tính toán và in ra báo cáo cuối cùng\n",
    "    print(\"\\nFinal Report:\")\n",
    "    print(f\"Mean Accuracy: {np.mean(accuracies)}\")\n",
    "    print(f\"Standard Deviation of Accuracy: {np.std(accuracies)}\")\n",
    "    \n",
    "    # In ra classification report cho từng fold\n",
    "    for i, report in enumerate(reports):\n",
    "        print(f\"\\nClassification Report for fold {i+1}:\")\n",
    "        print(classification_report(y.iloc[test_index], y_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 1...\n",
      "[LightGBM] [Info] Number of positive: 5842, number of negative: 41278\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013286 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29107\n",
      "[LightGBM] [Info] Number of data points in the train set: 47120, number of used features: 121\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123981 -> initscore=-1.955256\n",
      "[LightGBM] [Info] Start training from score -1.955256\n",
      "Accuracy for fold 1: 0.8845598845598845\n",
      "Training on fold 2...\n",
      "[LightGBM] [Info] Number of positive: 5857, number of negative: 41264\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015557 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29107\n",
      "[LightGBM] [Info] Number of data points in the train set: 47121, number of used features: 121\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.124297 -> initscore=-1.952353\n",
      "[LightGBM] [Info] Start training from score -1.952353\n",
      "Accuracy for fold 2: 0.8840407470288625\n",
      "Training on fold 3...\n",
      "[LightGBM] [Info] Number of positive: 5853, number of negative: 41268\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031066 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29107\n",
      "[LightGBM] [Info] Number of data points in the train set: 47121, number of used features: 121\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.124212 -> initscore=-1.953133\n",
      "[LightGBM] [Info] Start training from score -1.953133\n",
      "Accuracy for fold 3: 0.8826825127334466\n",
      "Training on fold 4...\n",
      "[LightGBM] [Info] Number of positive: 5836, number of negative: 41285\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025785 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29107\n",
      "[LightGBM] [Info] Number of data points in the train set: 47121, number of used features: 121\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123851 -> initscore=-1.956454\n",
      "[LightGBM] [Info] Start training from score -1.956454\n",
      "Accuracy for fold 4: 0.8831918505942276\n",
      "Training on fold 5...\n",
      "[LightGBM] [Info] Number of positive: 5820, number of negative: 41301\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022370 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29107\n",
      "[LightGBM] [Info] Number of data points in the train set: 47121, number of used features: 121\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123512 -> initscore=-1.959586\n",
      "[LightGBM] [Info] Start training from score -1.959586\n",
      "Accuracy for fold 5: 0.8805602716468591\n",
      "\n",
      "Final Report:\n",
      "Mean Accuracy: 0.883007053312656\n",
      "Standard Deviation of Accuracy: 0.0013860753748771162\n",
      "\n",
      "Classification Report for fold 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.98      0.94     10298\n",
      "         1.0       0.59      0.16      0.25      1482\n",
      "\n",
      "    accuracy                           0.88     11780\n",
      "   macro avg       0.74      0.57      0.59     11780\n",
      "weighted avg       0.85      0.88      0.85     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.98      0.94     10298\n",
      "         1.0       0.59      0.16      0.25      1482\n",
      "\n",
      "    accuracy                           0.88     11780\n",
      "   macro avg       0.74      0.57      0.59     11780\n",
      "weighted avg       0.85      0.88      0.85     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.98      0.94     10298\n",
      "         1.0       0.59      0.16      0.25      1482\n",
      "\n",
      "    accuracy                           0.88     11780\n",
      "   macro avg       0.74      0.57      0.59     11780\n",
      "weighted avg       0.85      0.88      0.85     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.98      0.94     10298\n",
      "         1.0       0.59      0.16      0.25      1482\n",
      "\n",
      "    accuracy                           0.88     11780\n",
      "   macro avg       0.74      0.57      0.59     11780\n",
      "weighted avg       0.85      0.88      0.85     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.98      0.94     10298\n",
      "         1.0       0.59      0.16      0.25      1482\n",
      "\n",
      "    accuracy                           0.88     11780\n",
      "   macro avg       0.74      0.57      0.59     11780\n",
      "weighted avg       0.85      0.88      0.85     11780\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_lightgbm_kfold(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost as cb\n",
    "\n",
    "def train_catboost_kfold(processed_data, k=5):\n",
    "    df = processed_data.copy()\n",
    "    warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "    \n",
    "    # Chia dữ liệu thành biến độc lập (X) và biến phụ thuộc (y)\n",
    "    X = df.drop('Status', axis=1)\n",
    "    y = df['Status']\n",
    "    \n",
    "    # Khởi tạo KFold\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    accuracies = []\n",
    "    reports = []\n",
    "\n",
    "    fold = 1\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        print(f\"Training on fold {fold}...\")\n",
    "        \n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Khởi tạo và huấn luyện mô hình CatBoost trên tập train\n",
    "        model = cb.CatBoostClassifier(verbose=0)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Dự đoán trên tập test\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Đánh giá mô hình\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "        reports.append(report)\n",
    "\n",
    "        print(f\"Accuracy for fold {fold}: {accuracy}\")\n",
    "        fold += 1\n",
    "\n",
    "    # Tính toán và in ra báo cáo cuối cùng\n",
    "    print(\"\\nFinal Report:\")\n",
    "    print(f\"Mean Accuracy: {np.mean(accuracies)}\")\n",
    "    print(f\"Standard Deviation of Accuracy: {np.std(accuracies)}\")\n",
    "    \n",
    "    # In ra classification report cho từng fold\n",
    "    for i, report in enumerate(reports):\n",
    "        print(f\"\\nClassification Report for fold {i+1}:\")\n",
    "        print(classification_report(y.iloc[test_index], y_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 1...\n",
      "Accuracy for fold 1: 0.8863424157541805\n",
      "Training on fold 2...\n",
      "Accuracy for fold 2: 0.884125636672326\n",
      "Training on fold 3...\n",
      "Accuracy for fold 3: 0.883955857385399\n",
      "Training on fold 4...\n",
      "Accuracy for fold 4: 0.8847198641765704\n",
      "Training on fold 5...\n",
      "Accuracy for fold 5: 0.8863327674023769\n",
      "\n",
      "Final Report:\n",
      "Mean Accuracy: 0.8850953082781705\n",
      "Standard Deviation of Accuracy: 0.0010455765657709426\n",
      "\n",
      "Classification Report for fold 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.98      0.94     10298\n",
      "         1.0       0.62      0.25      0.36      1482\n",
      "\n",
      "    accuracy                           0.89     11780\n",
      "   macro avg       0.76      0.61      0.65     11780\n",
      "weighted avg       0.87      0.89      0.86     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.98      0.94     10298\n",
      "         1.0       0.62      0.25      0.36      1482\n",
      "\n",
      "    accuracy                           0.89     11780\n",
      "   macro avg       0.76      0.61      0.65     11780\n",
      "weighted avg       0.87      0.89      0.86     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.98      0.94     10298\n",
      "         1.0       0.62      0.25      0.36      1482\n",
      "\n",
      "    accuracy                           0.89     11780\n",
      "   macro avg       0.76      0.61      0.65     11780\n",
      "weighted avg       0.87      0.89      0.86     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.98      0.94     10298\n",
      "         1.0       0.62      0.25      0.36      1482\n",
      "\n",
      "    accuracy                           0.89     11780\n",
      "   macro avg       0.76      0.61      0.65     11780\n",
      "weighted avg       0.87      0.89      0.86     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.98      0.94     10298\n",
      "         1.0       0.62      0.25      0.36      1482\n",
      "\n",
      "    accuracy                           0.89     11780\n",
      "   macro avg       0.76      0.61      0.65     11780\n",
      "weighted avg       0.87      0.89      0.86     11780\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_catboost_kfold(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nnson\\miniconda3\\Lib\\site-packages\\sklearn\\experimental\\enable_hist_gradient_boosting.py:16: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# train_hist_gradient_boosting_kfold\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "\n",
    "def train_hist_gradient_boosting_kfold(processed_data, k=5):\n",
    "    # Sao chép DataFrame và bỏ qua cảnh báo UndefinedMetricWarning\n",
    "    df = processed_data.copy()\n",
    "    warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "    \n",
    "    # Chia dữ liệu thành biến độc lập (X) và biến phụ thuộc (y)\n",
    "    X = df.drop('Status', axis=1)\n",
    "    y = df['Status']\n",
    "\n",
    "    # Khởi tạo KFold\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    accuracies = []\n",
    "    reports = []\n",
    "\n",
    "    fold = 1\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        print(f\"Training on fold {fold}...\")\n",
    "        \n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Khởi tạo và huấn luyện mô hình HistGradientBoostingClassifier trên tập train\n",
    "        model = HistGradientBoostingClassifier()\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Dự đoán trên tập test\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Đánh giá mô hình\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "        reports.append(report)\n",
    "\n",
    "        print(f\"Accuracy for fold {fold}: {accuracy}\")\n",
    "        fold += 1\n",
    "\n",
    "    # Tính toán và in ra báo cáo cuối cùng\n",
    "    print(\"\\nFinal Report:\")\n",
    "    print(f\"Mean Accuracy: {np.mean(accuracies)}\")\n",
    "    print(f\"Standard Deviation of Accuracy: {np.std(accuracies)}\")\n",
    "    \n",
    "    # In ra classification report cho từng fold\n",
    "    for i, report in enumerate(reports):\n",
    "        print(f\"\\nClassification Report for fold {i+1}:\")\n",
    "        print(classification_report(y.iloc[test_index], y_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 1...\n",
      "Accuracy for fold 1: 0.8829471182412358\n",
      "Training on fold 2...\n",
      "Accuracy for fold 2: 0.883955857385399\n",
      "Training on fold 3...\n",
      "Accuracy for fold 3: 0.8833616298811545\n",
      "Training on fold 4...\n",
      "Accuracy for fold 4: 0.881578947368421\n",
      "Training on fold 5...\n",
      "Accuracy for fold 5: 0.879881154499151\n",
      "\n",
      "Final Report:\n",
      "Mean Accuracy: 0.8823449414750723\n",
      "Standard Deviation of Accuracy: 0.001459336525757947\n",
      "\n",
      "Classification Report for fold 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.99      0.94     10298\n",
      "         1.0       0.62      0.12      0.20      1482\n",
      "\n",
      "    accuracy                           0.88     11780\n",
      "   macro avg       0.75      0.55      0.57     11780\n",
      "weighted avg       0.85      0.88      0.84     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.99      0.94     10298\n",
      "         1.0       0.62      0.12      0.20      1482\n",
      "\n",
      "    accuracy                           0.88     11780\n",
      "   macro avg       0.75      0.55      0.57     11780\n",
      "weighted avg       0.85      0.88      0.84     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.99      0.94     10298\n",
      "         1.0       0.62      0.12      0.20      1482\n",
      "\n",
      "    accuracy                           0.88     11780\n",
      "   macro avg       0.75      0.55      0.57     11780\n",
      "weighted avg       0.85      0.88      0.84     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.99      0.94     10298\n",
      "         1.0       0.62      0.12      0.20      1482\n",
      "\n",
      "    accuracy                           0.88     11780\n",
      "   macro avg       0.75      0.55      0.57     11780\n",
      "weighted avg       0.85      0.88      0.84     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.99      0.94     10298\n",
      "         1.0       0.62      0.12      0.20      1482\n",
      "\n",
      "    accuracy                           0.88     11780\n",
      "   macro avg       0.75      0.55      0.57     11780\n",
      "weighted avg       0.85      0.88      0.84     11780\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_hist_gradient_boosting_kfold(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_random_forest_kfold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def train_random_forest_kfold(processed_data, k=5):\n",
    "    # Sao chép DataFrame và bỏ qua cảnh báo UndefinedMetricWarning\n",
    "    df = processed_data.copy()\n",
    "    warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "    \n",
    "    # Chia dữ liệu thành biến độc lập (X) và biến phụ thuộc (y)\n",
    "    X = df.drop('Status', axis=1)\n",
    "    y = df['Status']\n",
    "\n",
    "    # Khởi tạo KFold\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    accuracies = []\n",
    "    reports = []\n",
    "\n",
    "    fold = 1\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        print(f\"Training on fold {fold}...\")\n",
    "        \n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Khởi tạo và huấn luyện mô hình RandomForestClassifier trên tập train\n",
    "        model = RandomForestClassifier()\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Dự đoán trên tập test\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Đánh giá mô hình\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "        reports.append(report)\n",
    "\n",
    "        print(f\"Accuracy for fold {fold}: {accuracy}\")\n",
    "        fold += 1\n",
    "\n",
    "    # Tính toán và in ra báo cáo cuối cùng\n",
    "    print(\"\\nFinal Report:\")\n",
    "    print(f\"Mean Accuracy: {np.mean(accuracies)}\")\n",
    "    print(f\"Standard Deviation of Accuracy: {np.std(accuracies)}\")\n",
    "    \n",
    "    # In ra classification report cho từng fold\n",
    "    for i, report in enumerate(reports):\n",
    "        print(f\"\\nClassification Report for fold {i+1}:\")\n",
    "        print(classification_report(y.iloc[test_index], y_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 1...\n",
      "Accuracy for fold 1: 0.8812494694847636\n",
      "Training on fold 2...\n",
      "Accuracy for fold 2: 0.8804753820033956\n",
      "Training on fold 3...\n",
      "Accuracy for fold 3: 0.8804753820033956\n",
      "Training on fold 4...\n",
      "Accuracy for fold 4: 0.8786926994906621\n",
      "Training on fold 5...\n",
      "Accuracy for fold 5: 0.8828522920203735\n",
      "\n",
      "Final Report:\n",
      "Mean Accuracy: 0.8807490450005181\n",
      "Standard Deviation of Accuracy: 0.001345541706440657\n",
      "\n",
      "Classification Report for fold 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.98      0.94     10298\n",
      "         1.0       0.59      0.22      0.32      1482\n",
      "\n",
      "    accuracy                           0.88     11780\n",
      "   macro avg       0.74      0.60      0.63     11780\n",
      "weighted avg       0.86      0.88      0.86     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.98      0.94     10298\n",
      "         1.0       0.59      0.22      0.32      1482\n",
      "\n",
      "    accuracy                           0.88     11780\n",
      "   macro avg       0.74      0.60      0.63     11780\n",
      "weighted avg       0.86      0.88      0.86     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.98      0.94     10298\n",
      "         1.0       0.59      0.22      0.32      1482\n",
      "\n",
      "    accuracy                           0.88     11780\n",
      "   macro avg       0.74      0.60      0.63     11780\n",
      "weighted avg       0.86      0.88      0.86     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.98      0.94     10298\n",
      "         1.0       0.59      0.22      0.32      1482\n",
      "\n",
      "    accuracy                           0.88     11780\n",
      "   macro avg       0.74      0.60      0.63     11780\n",
      "weighted avg       0.86      0.88      0.86     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.98      0.94     10298\n",
      "         1.0       0.59      0.22      0.32      1482\n",
      "\n",
      "    accuracy                           0.88     11780\n",
      "   macro avg       0.74      0.60      0.63     11780\n",
      "weighted avg       0.86      0.88      0.86     11780\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_random_forest_kfold(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_smote_RandomForest_kfold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "def train_smote_RandomForest_kfold(processed_data, k=5):\n",
    "    df = processed_data.copy()\n",
    "    warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "    \n",
    "    X = df.drop('Status', axis=1)\n",
    "    y = df['Status']\n",
    "\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    accuracies = []\n",
    "    reports = []\n",
    "\n",
    "    fold = 1\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        print(f\"Training on fold {fold}...\")\n",
    "        \n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # Áp dụng SMOTE cho tập train\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "        \n",
    "        # Khởi tạo và huấn luyện mô hình RandomForestClassifier trên tập train đã được resample\n",
    "        model = RandomForestClassifier(random_state=42)\n",
    "        model.fit(X_train_res, y_train_res)\n",
    "        \n",
    "        # Dự đoán trên tập test\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Đánh giá mô hình\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "        reports.append(report)\n",
    "\n",
    "        print(f\"Accuracy for fold {fold}: {accuracy}\")\n",
    "        fold += 1\n",
    "\n",
    "    # Tính toán và in ra báo cáo cuối cùng\n",
    "    print(\"\\nFinal Report:\")\n",
    "    print(f\"Mean Accuracy: {np.mean(accuracies)}\")\n",
    "    print(f\"Standard Deviation of Accuracy: {np.std(accuracies)}\")\n",
    "    \n",
    "    # In ra classification report cho từng fold\n",
    "    for i, report in enumerate(reports):\n",
    "        print(f\"\\nClassification Report for fold {i+1}:\")\n",
    "        print(classification_report(y.iloc[test_index], y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 1...\n",
      "Accuracy for fold 1: 0.8702996350055173\n",
      "Training on fold 2...\n",
      "Accuracy for fold 2: 0.8695246179966044\n",
      "Training on fold 3...\n",
      "Accuracy for fold 3: 0.8699490662139219\n",
      "Training on fold 4...\n",
      "Accuracy for fold 4: 0.8678268251273344\n",
      "Training on fold 5...\n",
      "Accuracy for fold 5: 0.866044142614601\n",
      "\n",
      "Final Report:\n",
      "Mean Accuracy: 0.8687288573915957\n",
      "Standard Deviation of Accuracy: 0.0015881336507073622\n",
      "\n",
      "Classification Report for fold 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.94      0.92     10298\n",
      "         1.0       0.46      0.37      0.41      1482\n",
      "\n",
      "    accuracy                           0.87     11780\n",
      "   macro avg       0.69      0.65      0.67     11780\n",
      "weighted avg       0.86      0.87      0.86     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.94      0.92     10298\n",
      "         1.0       0.46      0.37      0.41      1482\n",
      "\n",
      "    accuracy                           0.87     11780\n",
      "   macro avg       0.69      0.65      0.67     11780\n",
      "weighted avg       0.86      0.87      0.86     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.94      0.92     10298\n",
      "         1.0       0.46      0.37      0.41      1482\n",
      "\n",
      "    accuracy                           0.87     11780\n",
      "   macro avg       0.69      0.65      0.67     11780\n",
      "weighted avg       0.86      0.87      0.86     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.94      0.92     10298\n",
      "         1.0       0.46      0.37      0.41      1482\n",
      "\n",
      "    accuracy                           0.87     11780\n",
      "   macro avg       0.69      0.65      0.67     11780\n",
      "weighted avg       0.86      0.87      0.86     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.94      0.92     10298\n",
      "         1.0       0.46      0.37      0.41      1482\n",
      "\n",
      "    accuracy                           0.87     11780\n",
      "   macro avg       0.69      0.65      0.67     11780\n",
      "weighted avg       0.86      0.87      0.86     11780\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_smote_RandomForest_kfold(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_random_forest_class_weight_kfold\n",
    "\n",
    "# Imbalanced Learning Techniques - Class Weight Adjustment: Điều chỉnh trọng số lớp để mô hình tập trung hơn vào lớp thiểu số.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def train_random_forest_class_weight_kfold(processed_data, k=5):\n",
    "    # Sao chép DataFrame và bỏ qua cảnh báo UndefinedMetricWarning\n",
    "    df = processed_data.copy()\n",
    "    warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "    \n",
    "    # Chia dữ liệu thành biến độc lập (X) và biến phụ thuộc (y)\n",
    "    X = df.drop('Status', axis=1)\n",
    "    y = df['Status']\n",
    "\n",
    "    # Khởi tạo KFold\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    accuracies = []\n",
    "    reports = []\n",
    "\n",
    "    fold = 1\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        print(f\"Training on fold {fold}...\")\n",
    "        \n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Khởi tạo và huấn luyện mô hình RandomForestClassifier với class_weight='balanced'\n",
    "        model = RandomForestClassifier(class_weight='balanced')\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Dự đoán trên tập test\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Đánh giá mô hình\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "        reports.append(report)\n",
    "\n",
    "        print(f\"Accuracy for fold {fold}: {accuracy}\")\n",
    "        fold += 1\n",
    "\n",
    "    # Tính toán và in ra báo cáo cuối cùng\n",
    "    print(\"\\nFinal Report:\")\n",
    "    print(f\"Mean Accuracy: {np.mean(accuracies)}\")\n",
    "    print(f\"Standard Deviation of Accuracy: {np.std(accuracies)}\")\n",
    "    \n",
    "    # In ra classification report cho từng fold\n",
    "    for i, report in enumerate(reports):\n",
    "        print(f\"\\nClassification Report for fold {i+1}:\")\n",
    "        print(classification_report(y.iloc[test_index], y_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 1...\n",
      "Accuracy for fold 1: 0.8759018759018758\n",
      "Training on fold 2...\n",
      "Accuracy for fold 2: 0.8801358234295416\n",
      "Training on fold 3...\n",
      "Accuracy for fold 3: 0.8788624787775892\n",
      "Training on fold 4...\n",
      "Accuracy for fold 4: 0.8771646859083192\n",
      "Training on fold 5...\n",
      "Accuracy for fold 5: 0.8774193548387097\n",
      "\n",
      "Final Report:\n",
      "Mean Accuracy: 0.877896843771207\n",
      "Standard Deviation of Accuracy: 0.0014621510518750185\n",
      "\n",
      "Classification Report for fold 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.98      0.93     10298\n",
      "         1.0       0.55      0.15      0.24      1482\n",
      "\n",
      "    accuracy                           0.88     11780\n",
      "   macro avg       0.72      0.57      0.59     11780\n",
      "weighted avg       0.85      0.88      0.85     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.98      0.93     10298\n",
      "         1.0       0.55      0.15      0.24      1482\n",
      "\n",
      "    accuracy                           0.88     11780\n",
      "   macro avg       0.72      0.57      0.59     11780\n",
      "weighted avg       0.85      0.88      0.85     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.98      0.93     10298\n",
      "         1.0       0.55      0.15      0.24      1482\n",
      "\n",
      "    accuracy                           0.88     11780\n",
      "   macro avg       0.72      0.57      0.59     11780\n",
      "weighted avg       0.85      0.88      0.85     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.98      0.93     10298\n",
      "         1.0       0.55      0.15      0.24      1482\n",
      "\n",
      "    accuracy                           0.88     11780\n",
      "   macro avg       0.72      0.57      0.59     11780\n",
      "weighted avg       0.85      0.88      0.85     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.98      0.93     10298\n",
      "         1.0       0.55      0.15      0.24      1482\n",
      "\n",
      "    accuracy                           0.88     11780\n",
      "   macro avg       0.72      0.57      0.59     11780\n",
      "weighted avg       0.85      0.88      0.85     11780\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_random_forest_class_weight_kfold(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_random_forest_grid_search\n",
    "\n",
    "# Hyperparameter Tuning - Grid Search\n",
    "\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "\n",
    "def train_random_forest_grid_search(processed_data, k=5):\n",
    "    # Sao chép DataFrame và bỏ qua cảnh báo UndefinedMetricWarning\n",
    "    df = processed_data.copy()\n",
    "    warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "    \n",
    "    # Chia dữ liệu thành biến độc lập (X) và biến phụ thuộc (y)\n",
    "    X = df.drop('Status', axis=1)\n",
    "    y = df['Status']\n",
    "\n",
    "    # Khởi tạo KFold\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    # Thiết lập các tham số cho Grid Search\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "\n",
    "    # Khởi tạo Grid Search với RandomForestClassifier\n",
    "    grid_search = GridSearchCV(estimator=RandomForestClassifier(), param_grid=param_grid, cv=kf, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "\n",
    "    # Huấn luyện Grid Search trên toàn bộ dữ liệu\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    # Lấy mô hình tốt nhất từ Grid Search\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # In ra các tham số tốt nhất\n",
    "    print(\"Best parameters found: \", grid_search.best_params_)\n",
    "    print(\"Best cross-validation accuracy: \", grid_search.best_score_)\n",
    "\n",
    "    # Dự đoán và đánh giá mô hình tốt nhất trên toàn bộ tập dữ liệu\n",
    "    y_pred = best_model.predict(X)\n",
    "    print(\"Classification Report for best model:\")\n",
    "    print(classification_report(y, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Best parameters found:  {'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Best cross-validation accuracy:  0.8828033455497752\n",
      "Classification Report for best model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      1.00      0.97     51599\n",
      "         1.0       0.98      0.59      0.74      7302\n",
      "\n",
      "    accuracy                           0.95     58901\n",
      "   macro avg       0.96      0.80      0.86     58901\n",
      "weighted avg       0.95      0.95      0.94     58901\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_random_forest_grid_search(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_random_forest_random_search\n",
    "\n",
    "# Hyperparameter Tuning - Random Search\n",
    "\n",
    "from sklearn.model_selection import KFold, RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "def train_random_forest_random_search(processed_data, k=5):\n",
    "    # Sao chép DataFrame và bỏ qua cảnh báo UndefinedMetricWarning\n",
    "    df = processed_data.copy()\n",
    "    warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "    \n",
    "    # Chia dữ liệu thành biến độc lập (X) và biến phụ thuộc (y)\n",
    "    X = df.drop('Status', axis=1)\n",
    "    y = df['Status']\n",
    "\n",
    "    # Khởi tạo KFold\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    # Thiết lập các tham số cho Random Search\n",
    "    param_dist = {\n",
    "        'n_estimators': randint(50, 200),\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': randint(2, 11),\n",
    "        'min_samples_leaf': randint(1, 5)\n",
    "    }\n",
    "\n",
    "    # Khởi tạo Random Search với RandomForestClassifier\n",
    "    random_search = RandomizedSearchCV(estimator=RandomForestClassifier(), param_distributions=param_dist, n_iter=100, cv=kf, scoring='accuracy', n_jobs=-1, verbose=2, random_state=42)\n",
    "\n",
    "    # Huấn luyện Random Search trên toàn bộ dữ liệu\n",
    "    random_search.fit(X, y)\n",
    "\n",
    "    # Lấy mô hình tốt nhất từ Random Search\n",
    "    best_model = random_search.best_estimator_\n",
    "\n",
    "    # In ra các tham số tốt nhất\n",
    "    print(\"Best parameters found: \", random_search.best_params_)\n",
    "    print(\"Best cross-validation accuracy: \", random_search.best_score_)\n",
    "\n",
    "    # Dự đoán và đánh giá mô hình tốt nhất trên toàn bộ tập dữ liệu\n",
    "    y_pred = best_model.predict(X)\n",
    "    print(\"Classification Report for best model:\")\n",
    "    print(classification_report(y, y_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best parameters found:  {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 6, 'n_estimators': 116}\n",
      "Best cross-validation accuracy:  0.8829052030340356\n",
      "Classification Report for best model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      1.00      0.97     51599\n",
      "         1.0       0.99      0.61      0.75      7302\n",
      "\n",
      "    accuracy                           0.95     58901\n",
      "   macro avg       0.97      0.80      0.86     58901\n",
      "weighted avg       0.95      0.95      0.95     58901\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_random_forest_random_search(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_stacking_kfold\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def train_stacking_kfold(processed_data, k=5):\n",
    "    # Sao chép DataFrame và bỏ qua cảnh báo UndefinedMetricWarning\n",
    "    df = processed_data.copy()\n",
    "    warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "    \n",
    "    # Chia dữ liệu thành biến độc lập (X) và biến phụ thuộc (y)\n",
    "    X = df.drop('Status', axis=1)\n",
    "    y = df['Status']\n",
    "\n",
    "    # Khởi tạo KFold\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    accuracies = []\n",
    "    reports = []\n",
    "\n",
    "    fold = 1\n",
    "    for train_index, test_index in tqdm(kf.split(X), total=k, desc=\"K-Fold Progress\"):\n",
    "        print(f\"Training on fold {fold}...\")\n",
    "        \n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Khởi tạo các mô hình cơ bản\n",
    "        estimators = [\n",
    "            ('rf', RandomForestClassifier()),\n",
    "            ('gb', GradientBoostingClassifier())\n",
    "        ]\n",
    "        \n",
    "        # Khởi tạo và huấn luyện mô hình StackingClassifier trên tập train\n",
    "        model = StackingClassifier(\n",
    "            estimators=estimators,\n",
    "            final_estimator=LogisticRegression()\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Dự đoán trên tập test\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Đánh giá mô hình\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "        reports.append(report)\n",
    "\n",
    "        print(f\"Accuracy for fold {fold}: {accuracy}\")\n",
    "        fold += 1\n",
    "\n",
    "    # Tính toán và in ra báo cáo cuối cùng\n",
    "    print(\"\\nFinal Report:\")\n",
    "    print(f\"Mean Accuracy: {np.mean(accuracies)}\")\n",
    "    print(f\"Standard Deviation of Accuracy: {np.std(accuracies)}\")\n",
    "    \n",
    "    # In ra classification report cho từng fold\n",
    "    for i, report in enumerate(reports):\n",
    "        print(f\"\\nClassification Report for fold {i+1}:\")\n",
    "        print(classification_report(y.iloc[test_index], y_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K-Fold Progress:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K-Fold Progress:  20%|██        | 1/5 [11:31<46:06, 691.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for fold 1: 0.8830320006790595\n",
      "Training on fold 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K-Fold Progress:  40%|████      | 2/5 [22:59<34:29, 689.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for fold 2: 0.8820033955857386\n",
      "Training on fold 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K-Fold Progress:  60%|██████    | 3/5 [34:35<23:05, 692.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for fold 3: 0.8788624787775892\n",
      "Training on fold 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K-Fold Progress:  80%|████████  | 4/5 [46:22<11:38, 698.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for fold 4: 0.8823429541595925\n",
      "Training on fold 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K-Fold Progress: 100%|██████████| 5/5 [58:03<00:00, 696.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for fold 5: 0.8828522920203735\n",
      "\n",
      "Final Report:\n",
      "Mean Accuracy: 0.8818186242444707\n",
      "Standard Deviation of Accuracy: 0.0015224066324583058\n",
      "\n",
      "Classification Report for fold 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.97      0.94     10327\n",
      "         1.0       0.56      0.25      0.34      1453\n",
      "\n",
      "    accuracy                           0.88     11780\n",
      "   macro avg       0.73      0.61      0.64     11780\n",
      "weighted avg       0.86      0.88      0.86     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.97      0.94     10327\n",
      "         1.0       0.56      0.25      0.34      1453\n",
      "\n",
      "    accuracy                           0.88     11780\n",
      "   macro avg       0.73      0.61      0.64     11780\n",
      "weighted avg       0.86      0.88      0.86     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.97      0.94     10327\n",
      "         1.0       0.56      0.25      0.34      1453\n",
      "\n",
      "    accuracy                           0.88     11780\n",
      "   macro avg       0.73      0.61      0.64     11780\n",
      "weighted avg       0.86      0.88      0.86     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.97      0.94     10327\n",
      "         1.0       0.56      0.25      0.34      1453\n",
      "\n",
      "    accuracy                           0.88     11780\n",
      "   macro avg       0.73      0.61      0.64     11780\n",
      "weighted avg       0.86      0.88      0.86     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.97      0.94     10327\n",
      "         1.0       0.56      0.25      0.34      1453\n",
      "\n",
      "    accuracy                           0.88     11780\n",
      "   macro avg       0.73      0.61      0.64     11780\n",
      "weighted avg       0.86      0.88      0.86     11780\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_stacking_kfold(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_smote_deep_learning_kfold\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ProgbarLogger\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "def build_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=input_shape, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_smote_deep_learning_kfold(processed_data, k=5, epochs=50, batch_size=32):\n",
    "    df = processed_data.copy()\n",
    "    warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "    \n",
    "    X = df.drop('Status', axis=1)\n",
    "    y = df['Status']\n",
    "\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    accuracies = []\n",
    "    reports = []\n",
    "\n",
    "    fold = 1\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        print(f\"Training on fold {fold}...\")\n",
    "        \n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # Áp dụng SMOTE cho tập train\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_res, y_train_res = smote.fit_resample(X_train, y_train)        \n",
    "\n",
    "        # Xây dựng mô hình\n",
    "        model = build_model(X_train.shape[1])\n",
    "        \n",
    "        # Đào tạo mô hình với ProgbarLogger\n",
    "        model.fit(X_train_res, y_train_res, epochs=epochs, batch_size=batch_size, verbose=1, \n",
    "                  validation_data=(X_test, y_test), callbacks=[ProgbarLogger()])\n",
    "        \n",
    "        # Dự đoán trên tập test\n",
    "        y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "        \n",
    "        # Đánh giá mô hình\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "        reports.append(report)\n",
    "\n",
    "        print(f\"Accuracy for fold {fold}: {accuracy}\")\n",
    "        fold += 1\n",
    "\n",
    "    # Tính toán và in ra báo cáo cuối cùng\n",
    "    print(\"\\nFinal Report:\")\n",
    "    print(f\"Mean Accuracy: {np.mean(accuracies)}\")\n",
    "    print(f\"Standard Deviation of Accuracy: {np.std(accuracies)}\")\n",
    "    \n",
    "    # In ra classification report cho từng fold\n",
    "    for i, report in enumerate(reports):\n",
    "        print(f\"\\nClassification Report for fold {i+1}:\")\n",
    "        print(classification_report(y.iloc[test_index], y_pred, zero_division=0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 1...\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 791us/step - accuracy: 0.7345 - loss: 0.5552 - val_accuracy: 0.8134 - val_loss: 0.4834\n",
      "Epoch 2/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 718us/step - accuracy: 0.7446 - loss: 0.5265 - val_accuracy: 0.7625 - val_loss: 0.5452\n",
      "Epoch 3/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 742us/step - accuracy: 0.7461 - loss: 0.5230 - val_accuracy: 0.7998 - val_loss: 0.4726\n",
      "Epoch 4/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 735us/step - accuracy: 0.7488 - loss: 0.5200 - val_accuracy: 0.7925 - val_loss: 0.5275\n",
      "Epoch 5/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 748us/step - accuracy: 0.7462 - loss: 0.5180 - val_accuracy: 0.7594 - val_loss: 0.5482\n",
      "Epoch 6/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 718us/step - accuracy: 0.7537 - loss: 0.5086 - val_accuracy: 0.7948 - val_loss: 0.4906\n",
      "Epoch 7/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 757us/step - accuracy: 0.7507 - loss: 0.5109 - val_accuracy: 0.7711 - val_loss: 0.5311\n",
      "Epoch 8/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 724us/step - accuracy: 0.7519 - loss: 0.5085 - val_accuracy: 0.7567 - val_loss: 0.5460\n",
      "Epoch 9/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 757us/step - accuracy: 0.7543 - loss: 0.5040 - val_accuracy: 0.7370 - val_loss: 0.5559\n",
      "Epoch 10/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 727us/step - accuracy: 0.7531 - loss: 0.5028 - val_accuracy: 0.7095 - val_loss: 0.5626\n",
      "Epoch 11/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 743us/step - accuracy: 0.7547 - loss: 0.5019 - val_accuracy: 0.7725 - val_loss: 0.5335\n",
      "Epoch 12/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 720us/step - accuracy: 0.7572 - loss: 0.4990 - val_accuracy: 0.8015 - val_loss: 0.4669\n",
      "Epoch 13/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 746us/step - accuracy: 0.7582 - loss: 0.4960 - val_accuracy: 0.7754 - val_loss: 0.5398\n",
      "Epoch 14/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 724us/step - accuracy: 0.7590 - loss: 0.4940 - val_accuracy: 0.7962 - val_loss: 0.4801\n",
      "Epoch 15/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 749us/step - accuracy: 0.7587 - loss: 0.4929 - val_accuracy: 0.8072 - val_loss: 0.4614\n",
      "Epoch 16/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 723us/step - accuracy: 0.7582 - loss: 0.4936 - val_accuracy: 0.7959 - val_loss: 0.4847\n",
      "Epoch 17/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 750us/step - accuracy: 0.7626 - loss: 0.4894 - val_accuracy: 0.8069 - val_loss: 0.4879\n",
      "Epoch 18/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 717us/step - accuracy: 0.7622 - loss: 0.4877 - val_accuracy: 0.7916 - val_loss: 0.4791\n",
      "Epoch 19/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 745us/step - accuracy: 0.7659 - loss: 0.4845 - val_accuracy: 0.7781 - val_loss: 0.5085\n",
      "Epoch 20/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 719us/step - accuracy: 0.7653 - loss: 0.4842 - val_accuracy: 0.8132 - val_loss: 0.4453\n",
      "Epoch 21/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 745us/step - accuracy: 0.7647 - loss: 0.4815 - val_accuracy: 0.7555 - val_loss: 0.5231\n",
      "Epoch 22/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 726us/step - accuracy: 0.7650 - loss: 0.4810 - val_accuracy: 0.7607 - val_loss: 0.5324\n",
      "Epoch 23/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 776us/step - accuracy: 0.7644 - loss: 0.4793 - val_accuracy: 0.7498 - val_loss: 0.5806\n",
      "Epoch 24/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 753us/step - accuracy: 0.7660 - loss: 0.4792 - val_accuracy: 0.7980 - val_loss: 0.4817\n",
      "Epoch 25/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 721us/step - accuracy: 0.7685 - loss: 0.4738 - val_accuracy: 0.7528 - val_loss: 0.5129\n",
      "Epoch 26/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 765us/step - accuracy: 0.7699 - loss: 0.4702 - val_accuracy: 0.8066 - val_loss: 0.4387\n",
      "Epoch 27/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 728us/step - accuracy: 0.7694 - loss: 0.4715 - val_accuracy: 0.7693 - val_loss: 0.5414\n",
      "Epoch 28/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 756us/step - accuracy: 0.7706 - loss: 0.4715 - val_accuracy: 0.8210 - val_loss: 0.4555\n",
      "Epoch 29/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 730us/step - accuracy: 0.7726 - loss: 0.4700 - val_accuracy: 0.7470 - val_loss: 0.5549\n",
      "Epoch 30/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 747us/step - accuracy: 0.7711 - loss: 0.4694 - val_accuracy: 0.7860 - val_loss: 0.4805\n",
      "Epoch 31/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 720us/step - accuracy: 0.7737 - loss: 0.4671 - val_accuracy: 0.7004 - val_loss: 0.5921\n",
      "Epoch 32/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 758us/step - accuracy: 0.7746 - loss: 0.4644 - val_accuracy: 0.8018 - val_loss: 0.4634\n",
      "Epoch 33/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 750us/step - accuracy: 0.7759 - loss: 0.4613 - val_accuracy: 0.7951 - val_loss: 0.4814\n",
      "Epoch 34/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 726us/step - accuracy: 0.7747 - loss: 0.4618 - val_accuracy: 0.7525 - val_loss: 0.5259\n",
      "Epoch 35/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 746us/step - accuracy: 0.7768 - loss: 0.4575 - val_accuracy: 0.7631 - val_loss: 0.5248\n",
      "Epoch 36/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 721us/step - accuracy: 0.7776 - loss: 0.4556 - val_accuracy: 0.7725 - val_loss: 0.5303\n",
      "Epoch 37/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 747us/step - accuracy: 0.7799 - loss: 0.4562 - val_accuracy: 0.7993 - val_loss: 0.4618\n",
      "Epoch 38/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 725us/step - accuracy: 0.7796 - loss: 0.4555 - val_accuracy: 0.7524 - val_loss: 0.5290\n",
      "Epoch 39/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 745us/step - accuracy: 0.7829 - loss: 0.4490 - val_accuracy: 0.7871 - val_loss: 0.5091\n",
      "Epoch 40/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 720us/step - accuracy: 0.7826 - loss: 0.4491 - val_accuracy: 0.7717 - val_loss: 0.5131\n",
      "Epoch 41/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 752us/step - accuracy: 0.7841 - loss: 0.4468 - val_accuracy: 0.7575 - val_loss: 0.5104\n",
      "Epoch 42/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 722us/step - accuracy: 0.7845 - loss: 0.4458 - val_accuracy: 0.7868 - val_loss: 0.4680\n",
      "Epoch 43/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 751us/step - accuracy: 0.7903 - loss: 0.4419 - val_accuracy: 0.7737 - val_loss: 0.4920\n",
      "Epoch 44/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 747us/step - accuracy: 0.7868 - loss: 0.4444 - val_accuracy: 0.7658 - val_loss: 0.5375\n",
      "Epoch 45/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 722us/step - accuracy: 0.7884 - loss: 0.4402 - val_accuracy: 0.7407 - val_loss: 0.5365\n",
      "Epoch 46/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 746us/step - accuracy: 0.7921 - loss: 0.4356 - val_accuracy: 0.7349 - val_loss: 0.5567\n",
      "Epoch 47/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 726us/step - accuracy: 0.7928 - loss: 0.4356 - val_accuracy: 0.8122 - val_loss: 0.4265\n",
      "Epoch 48/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 748us/step - accuracy: 0.7909 - loss: 0.4353 - val_accuracy: 0.7998 - val_loss: 0.4721\n",
      "Epoch 49/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 719us/step - accuracy: 0.7946 - loss: 0.4338 - val_accuracy: 0.7923 - val_loss: 0.4970\n",
      "Epoch 50/50\n",
      "\u001b[1m2581/2581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 758us/step - accuracy: 0.7942 - loss: 0.4320 - val_accuracy: 0.6684 - val_loss: 0.6163\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step\n",
      "Accuracy for fold 1: 0.6684491978609626\n",
      "Training on fold 2...\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 804us/step - accuracy: 0.7344 - loss: 0.5521 - val_accuracy: 0.8037 - val_loss: 0.4641\n",
      "Epoch 2/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 714us/step - accuracy: 0.7482 - loss: 0.5210 - val_accuracy: 0.7957 - val_loss: 0.4997\n",
      "Epoch 3/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 755us/step - accuracy: 0.7560 - loss: 0.5100 - val_accuracy: 0.7479 - val_loss: 0.5724\n",
      "Epoch 4/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 723us/step - accuracy: 0.7533 - loss: 0.5111 - val_accuracy: 0.6764 - val_loss: 0.6805\n",
      "Epoch 5/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 750us/step - accuracy: 0.7564 - loss: 0.5082 - val_accuracy: 0.7520 - val_loss: 0.5373\n",
      "Epoch 6/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 727us/step - accuracy: 0.7528 - loss: 0.5080 - val_accuracy: 0.7937 - val_loss: 0.4775\n",
      "Epoch 7/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 741us/step - accuracy: 0.7583 - loss: 0.4997 - val_accuracy: 0.7361 - val_loss: 0.5667\n",
      "Epoch 8/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 724us/step - accuracy: 0.7604 - loss: 0.4981 - val_accuracy: 0.7884 - val_loss: 0.4834\n",
      "Epoch 9/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 746us/step - accuracy: 0.7568 - loss: 0.5006 - val_accuracy: 0.8053 - val_loss: 0.4578\n",
      "Epoch 10/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 727us/step - accuracy: 0.7599 - loss: 0.4968 - val_accuracy: 0.7864 - val_loss: 0.4880\n",
      "Epoch 11/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 734us/step - accuracy: 0.7608 - loss: 0.4942 - val_accuracy: 0.7989 - val_loss: 0.4782\n",
      "Epoch 12/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 732us/step - accuracy: 0.7605 - loss: 0.4969 - val_accuracy: 0.7972 - val_loss: 0.4719\n",
      "Epoch 13/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 763us/step - accuracy: 0.7603 - loss: 0.4953 - val_accuracy: 0.7266 - val_loss: 0.5881\n",
      "Epoch 14/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 726us/step - accuracy: 0.7603 - loss: 0.4930 - val_accuracy: 0.7907 - val_loss: 0.5028\n",
      "Epoch 15/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 754us/step - accuracy: 0.7621 - loss: 0.4924 - val_accuracy: 0.7855 - val_loss: 0.4712\n",
      "Epoch 16/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 720us/step - accuracy: 0.7627 - loss: 0.4922 - val_accuracy: 0.7677 - val_loss: 0.5121\n",
      "Epoch 17/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 752us/step - accuracy: 0.7660 - loss: 0.4867 - val_accuracy: 0.7929 - val_loss: 0.4828\n",
      "Epoch 18/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 730us/step - accuracy: 0.7632 - loss: 0.4879 - val_accuracy: 0.7992 - val_loss: 0.4572\n",
      "Epoch 19/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 753us/step - accuracy: 0.7654 - loss: 0.4852 - val_accuracy: 0.7683 - val_loss: 0.5055\n",
      "Epoch 20/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 726us/step - accuracy: 0.7653 - loss: 0.4867 - val_accuracy: 0.7508 - val_loss: 0.5091\n",
      "Epoch 21/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 751us/step - accuracy: 0.7675 - loss: 0.4805 - val_accuracy: 0.7185 - val_loss: 0.5856\n",
      "Epoch 22/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 733us/step - accuracy: 0.7690 - loss: 0.4778 - val_accuracy: 0.7617 - val_loss: 0.4928\n",
      "Epoch 23/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 754us/step - accuracy: 0.7702 - loss: 0.4777 - val_accuracy: 0.7726 - val_loss: 0.5378\n",
      "Epoch 24/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 737us/step - accuracy: 0.7725 - loss: 0.4738 - val_accuracy: 0.7530 - val_loss: 0.5186\n",
      "Epoch 25/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 757us/step - accuracy: 0.7722 - loss: 0.4730 - val_accuracy: 0.7654 - val_loss: 0.5342\n",
      "Epoch 26/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 726us/step - accuracy: 0.7728 - loss: 0.4722 - val_accuracy: 0.7825 - val_loss: 0.4927\n",
      "Epoch 27/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 761us/step - accuracy: 0.7725 - loss: 0.4730 - val_accuracy: 0.7788 - val_loss: 0.5121\n",
      "Epoch 28/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 739us/step - accuracy: 0.7728 - loss: 0.4717 - val_accuracy: 0.7542 - val_loss: 0.5297\n",
      "Epoch 29/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 749us/step - accuracy: 0.7732 - loss: 0.4697 - val_accuracy: 0.7848 - val_loss: 0.4912\n",
      "Epoch 30/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 752us/step - accuracy: 0.7758 - loss: 0.4660 - val_accuracy: 0.7774 - val_loss: 0.5057\n",
      "Epoch 31/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 738us/step - accuracy: 0.7760 - loss: 0.4675 - val_accuracy: 0.7758 - val_loss: 0.5001\n",
      "Epoch 32/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 751us/step - accuracy: 0.7761 - loss: 0.4658 - val_accuracy: 0.7581 - val_loss: 0.5201\n",
      "Epoch 33/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 729us/step - accuracy: 0.7761 - loss: 0.4635 - val_accuracy: 0.7818 - val_loss: 0.5034\n",
      "Epoch 34/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 756us/step - accuracy: 0.7734 - loss: 0.4660 - val_accuracy: 0.7872 - val_loss: 0.4843\n",
      "Epoch 35/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 726us/step - accuracy: 0.7782 - loss: 0.4575 - val_accuracy: 0.7269 - val_loss: 0.5673\n",
      "Epoch 36/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 753us/step - accuracy: 0.7800 - loss: 0.4584 - val_accuracy: 0.7596 - val_loss: 0.5255\n",
      "Epoch 37/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 744us/step - accuracy: 0.7807 - loss: 0.4569 - val_accuracy: 0.7710 - val_loss: 0.5468\n",
      "Epoch 38/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 755us/step - accuracy: 0.7789 - loss: 0.4552 - val_accuracy: 0.7434 - val_loss: 0.5320\n",
      "Epoch 39/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 761us/step - accuracy: 0.7805 - loss: 0.4576 - val_accuracy: 0.7946 - val_loss: 0.4798\n",
      "Epoch 40/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 732us/step - accuracy: 0.7813 - loss: 0.4536 - val_accuracy: 0.7778 - val_loss: 0.5224\n",
      "Epoch 41/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 755us/step - accuracy: 0.7846 - loss: 0.4487 - val_accuracy: 0.7731 - val_loss: 0.5068\n",
      "Epoch 42/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 733us/step - accuracy: 0.7852 - loss: 0.4492 - val_accuracy: 0.7511 - val_loss: 0.5304\n",
      "Epoch 43/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 758us/step - accuracy: 0.7845 - loss: 0.4503 - val_accuracy: 0.7733 - val_loss: 0.5027\n",
      "Epoch 44/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 728us/step - accuracy: 0.7871 - loss: 0.4424 - val_accuracy: 0.7489 - val_loss: 0.5531\n",
      "Epoch 45/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 752us/step - accuracy: 0.7854 - loss: 0.4468 - val_accuracy: 0.7924 - val_loss: 0.5158\n",
      "Epoch 46/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 762us/step - accuracy: 0.7854 - loss: 0.4474 - val_accuracy: 0.7963 - val_loss: 0.4699\n",
      "Epoch 47/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 729us/step - accuracy: 0.7870 - loss: 0.4459 - val_accuracy: 0.7223 - val_loss: 0.5745\n",
      "Epoch 48/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 750us/step - accuracy: 0.7871 - loss: 0.4444 - val_accuracy: 0.7750 - val_loss: 0.4955\n",
      "Epoch 49/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 729us/step - accuracy: 0.7907 - loss: 0.4391 - val_accuracy: 0.7722 - val_loss: 0.4999\n",
      "Epoch 50/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 750us/step - accuracy: 0.7897 - loss: 0.4418 - val_accuracy: 0.7778 - val_loss: 0.5109\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step\n",
      "Accuracy for fold 2: 0.7777589134125636\n",
      "Training on fold 3...\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 790us/step - accuracy: 0.7304 - loss: 0.5583 - val_accuracy: 0.7756 - val_loss: 0.5168\n",
      "Epoch 2/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 717us/step - accuracy: 0.7482 - loss: 0.5225 - val_accuracy: 0.7949 - val_loss: 0.5318\n",
      "Epoch 3/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 747us/step - accuracy: 0.7468 - loss: 0.5197 - val_accuracy: 0.7893 - val_loss: 0.5032\n",
      "Epoch 4/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 716us/step - accuracy: 0.7466 - loss: 0.5190 - val_accuracy: 0.7949 - val_loss: 0.4818\n",
      "Epoch 5/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 742us/step - accuracy: 0.7491 - loss: 0.5143 - val_accuracy: 0.7833 - val_loss: 0.5266\n",
      "Epoch 6/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 726us/step - accuracy: 0.7503 - loss: 0.5129 - val_accuracy: 0.7959 - val_loss: 0.4746\n",
      "Epoch 7/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 715us/step - accuracy: 0.7506 - loss: 0.5105 - val_accuracy: 0.7799 - val_loss: 0.5335\n",
      "Epoch 8/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 729us/step - accuracy: 0.7528 - loss: 0.5054 - val_accuracy: 0.7827 - val_loss: 0.5165\n",
      "Epoch 9/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 726us/step - accuracy: 0.7552 - loss: 0.5038 - val_accuracy: 0.8058 - val_loss: 0.4804\n",
      "Epoch 10/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 746us/step - accuracy: 0.7535 - loss: 0.5022 - val_accuracy: 0.7374 - val_loss: 0.5928\n",
      "Epoch 11/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 719us/step - accuracy: 0.7534 - loss: 0.5028 - val_accuracy: 0.8031 - val_loss: 0.4756\n",
      "Epoch 12/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 757us/step - accuracy: 0.7565 - loss: 0.4975 - val_accuracy: 0.7811 - val_loss: 0.5028\n",
      "Epoch 13/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 730us/step - accuracy: 0.7518 - loss: 0.4992 - val_accuracy: 0.7939 - val_loss: 0.4933\n",
      "Epoch 14/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 751us/step - accuracy: 0.7549 - loss: 0.4962 - val_accuracy: 0.8101 - val_loss: 0.4557\n",
      "Epoch 15/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 723us/step - accuracy: 0.7593 - loss: 0.4938 - val_accuracy: 0.7941 - val_loss: 0.5100\n",
      "Epoch 16/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 754us/step - accuracy: 0.7555 - loss: 0.4936 - val_accuracy: 0.8049 - val_loss: 0.4811\n",
      "Epoch 17/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 727us/step - accuracy: 0.7626 - loss: 0.4844 - val_accuracy: 0.7350 - val_loss: 0.5288\n",
      "Epoch 18/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 753us/step - accuracy: 0.7579 - loss: 0.4912 - val_accuracy: 0.7763 - val_loss: 0.5198\n",
      "Epoch 19/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 749us/step - accuracy: 0.7609 - loss: 0.4873 - val_accuracy: 0.7913 - val_loss: 0.5025\n",
      "Epoch 20/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 736us/step - accuracy: 0.7635 - loss: 0.4836 - val_accuracy: 0.7941 - val_loss: 0.5113\n",
      "Epoch 21/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 760us/step - accuracy: 0.7597 - loss: 0.4849 - val_accuracy: 0.7929 - val_loss: 0.4813\n",
      "Epoch 22/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 724us/step - accuracy: 0.7632 - loss: 0.4808 - val_accuracy: 0.7702 - val_loss: 0.5302\n",
      "Epoch 23/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 753us/step - accuracy: 0.7648 - loss: 0.4806 - val_accuracy: 0.8124 - val_loss: 0.4899\n",
      "Epoch 24/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 717us/step - accuracy: 0.7657 - loss: 0.4789 - val_accuracy: 0.7592 - val_loss: 0.5302\n",
      "Epoch 25/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 749us/step - accuracy: 0.7667 - loss: 0.4769 - val_accuracy: 0.7297 - val_loss: 0.6042\n",
      "Epoch 26/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 730us/step - accuracy: 0.7662 - loss: 0.4762 - val_accuracy: 0.7958 - val_loss: 0.5182\n",
      "Epoch 27/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 752us/step - accuracy: 0.7672 - loss: 0.4786 - val_accuracy: 0.7776 - val_loss: 0.5087\n",
      "Epoch 28/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 724us/step - accuracy: 0.7638 - loss: 0.4804 - val_accuracy: 0.8084 - val_loss: 0.4808\n",
      "Epoch 29/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 749us/step - accuracy: 0.7649 - loss: 0.4748 - val_accuracy: 0.8006 - val_loss: 0.4812\n",
      "Epoch 30/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 730us/step - accuracy: 0.7686 - loss: 0.4745 - val_accuracy: 0.7885 - val_loss: 0.5012\n",
      "Epoch 31/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 747us/step - accuracy: 0.7679 - loss: 0.4724 - val_accuracy: 0.8126 - val_loss: 0.4656\n",
      "Epoch 32/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 752us/step - accuracy: 0.7719 - loss: 0.4674 - val_accuracy: 0.7963 - val_loss: 0.4765\n",
      "Epoch 33/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 732us/step - accuracy: 0.7721 - loss: 0.4678 - val_accuracy: 0.7874 - val_loss: 0.5467\n",
      "Epoch 34/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 761us/step - accuracy: 0.7698 - loss: 0.4674 - val_accuracy: 0.7925 - val_loss: 0.5222\n",
      "Epoch 35/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 733us/step - accuracy: 0.7713 - loss: 0.4679 - val_accuracy: 0.7988 - val_loss: 0.4945\n",
      "Epoch 36/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 753us/step - accuracy: 0.7700 - loss: 0.4683 - val_accuracy: 0.7616 - val_loss: 0.5280\n",
      "Epoch 37/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 726us/step - accuracy: 0.7728 - loss: 0.4655 - val_accuracy: 0.7930 - val_loss: 0.5161\n",
      "Epoch 38/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 748us/step - accuracy: 0.7739 - loss: 0.4629 - val_accuracy: 0.7868 - val_loss: 0.5172\n",
      "Epoch 39/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 732us/step - accuracy: 0.7751 - loss: 0.4601 - val_accuracy: 0.8019 - val_loss: 0.5129\n",
      "Epoch 40/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 749us/step - accuracy: 0.7721 - loss: 0.4630 - val_accuracy: 0.7785 - val_loss: 0.5356\n",
      "Epoch 41/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 754us/step - accuracy: 0.7800 - loss: 0.4559 - val_accuracy: 0.8101 - val_loss: 0.4435\n",
      "Epoch 42/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 729us/step - accuracy: 0.7765 - loss: 0.4576 - val_accuracy: 0.7610 - val_loss: 0.5321\n",
      "Epoch 43/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 750us/step - accuracy: 0.7801 - loss: 0.4545 - val_accuracy: 0.7654 - val_loss: 0.5290\n",
      "Epoch 44/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 731us/step - accuracy: 0.7793 - loss: 0.4554 - val_accuracy: 0.7868 - val_loss: 0.5223\n",
      "Epoch 45/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 746us/step - accuracy: 0.7775 - loss: 0.4564 - val_accuracy: 0.7757 - val_loss: 0.5178\n",
      "Epoch 46/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 726us/step - accuracy: 0.7796 - loss: 0.4530 - val_accuracy: 0.7653 - val_loss: 0.5418\n",
      "Epoch 47/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 756us/step - accuracy: 0.7783 - loss: 0.4528 - val_accuracy: 0.7832 - val_loss: 0.5163\n",
      "Epoch 48/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 755us/step - accuracy: 0.7828 - loss: 0.4476 - val_accuracy: 0.7656 - val_loss: 0.5356\n",
      "Epoch 49/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 730us/step - accuracy: 0.7819 - loss: 0.4478 - val_accuracy: 0.7594 - val_loss: 0.5291\n",
      "Epoch 50/50\n",
      "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 753us/step - accuracy: 0.7821 - loss: 0.4513 - val_accuracy: 0.7553 - val_loss: 0.5443\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step\n",
      "Accuracy for fold 3: 0.7553480475382003\n",
      "Training on fold 4...\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 743us/step - accuracy: 0.7316 - loss: 0.5526 - val_accuracy: 0.7834 - val_loss: 0.5118\n",
      "Epoch 2/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 682us/step - accuracy: 0.7444 - loss: 0.5260 - val_accuracy: 0.7847 - val_loss: 0.4889\n",
      "Epoch 3/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 683us/step - accuracy: 0.7501 - loss: 0.5152 - val_accuracy: 0.7167 - val_loss: 0.5881\n",
      "Epoch 4/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 719us/step - accuracy: 0.7495 - loss: 0.5132 - val_accuracy: 0.7563 - val_loss: 0.5356\n",
      "Epoch 5/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 687us/step - accuracy: 0.7512 - loss: 0.5104 - val_accuracy: 0.7857 - val_loss: 0.5008\n",
      "Epoch 6/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 716us/step - accuracy: 0.7552 - loss: 0.5053 - val_accuracy: 0.7595 - val_loss: 0.5259\n",
      "Epoch 7/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 703us/step - accuracy: 0.7527 - loss: 0.5061 - val_accuracy: 0.7396 - val_loss: 0.5525\n",
      "Epoch 8/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 724us/step - accuracy: 0.7545 - loss: 0.5038 - val_accuracy: 0.7765 - val_loss: 0.4990\n",
      "Epoch 9/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 697us/step - accuracy: 0.7548 - loss: 0.5014 - val_accuracy: 0.8161 - val_loss: 0.4750\n",
      "Epoch 10/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 721us/step - accuracy: 0.7568 - loss: 0.4981 - val_accuracy: 0.7846 - val_loss: 0.4996\n",
      "Epoch 11/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 697us/step - accuracy: 0.7572 - loss: 0.4959 - val_accuracy: 0.7630 - val_loss: 0.5362\n",
      "Epoch 12/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 728us/step - accuracy: 0.7594 - loss: 0.4943 - val_accuracy: 0.7848 - val_loss: 0.5174\n",
      "Epoch 13/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 712us/step - accuracy: 0.7574 - loss: 0.4949 - val_accuracy: 0.7999 - val_loss: 0.4582\n",
      "Epoch 14/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 735us/step - accuracy: 0.7591 - loss: 0.4926 - val_accuracy: 0.7717 - val_loss: 0.5382\n",
      "Epoch 15/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 707us/step - accuracy: 0.7634 - loss: 0.4889 - val_accuracy: 0.7699 - val_loss: 0.5341\n",
      "Epoch 16/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 734us/step - accuracy: 0.7597 - loss: 0.4899 - val_accuracy: 0.8178 - val_loss: 0.4355\n",
      "Epoch 17/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 697us/step - accuracy: 0.7616 - loss: 0.4880 - val_accuracy: 0.7689 - val_loss: 0.5291\n",
      "Epoch 18/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 743us/step - accuracy: 0.7593 - loss: 0.4881 - val_accuracy: 0.7638 - val_loss: 0.5538\n",
      "Epoch 19/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 715us/step - accuracy: 0.7632 - loss: 0.4867 - val_accuracy: 0.7873 - val_loss: 0.5250\n",
      "Epoch 20/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 736us/step - accuracy: 0.7635 - loss: 0.4811 - val_accuracy: 0.7738 - val_loss: 0.5272\n",
      "Epoch 21/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 709us/step - accuracy: 0.7679 - loss: 0.4782 - val_accuracy: 0.7825 - val_loss: 0.5082\n",
      "Epoch 22/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 728us/step - accuracy: 0.7661 - loss: 0.4801 - val_accuracy: 0.7913 - val_loss: 0.4587\n",
      "Epoch 23/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 701us/step - accuracy: 0.7690 - loss: 0.4768 - val_accuracy: 0.7608 - val_loss: 0.5384\n",
      "Epoch 24/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 733us/step - accuracy: 0.7668 - loss: 0.4759 - val_accuracy: 0.7970 - val_loss: 0.4673\n",
      "Epoch 25/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 699us/step - accuracy: 0.7652 - loss: 0.4766 - val_accuracy: 0.7551 - val_loss: 0.5259\n",
      "Epoch 26/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 728us/step - accuracy: 0.7731 - loss: 0.4701 - val_accuracy: 0.7820 - val_loss: 0.5312\n",
      "Epoch 27/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 698us/step - accuracy: 0.7685 - loss: 0.4768 - val_accuracy: 0.7847 - val_loss: 0.4837\n",
      "Epoch 28/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 738us/step - accuracy: 0.7709 - loss: 0.4733 - val_accuracy: 0.6961 - val_loss: 0.5977\n",
      "Epoch 29/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 716us/step - accuracy: 0.7702 - loss: 0.4724 - val_accuracy: 0.7996 - val_loss: 0.4831\n",
      "Epoch 30/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 733us/step - accuracy: 0.7727 - loss: 0.4694 - val_accuracy: 0.7542 - val_loss: 0.5405\n",
      "Epoch 31/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 720us/step - accuracy: 0.7766 - loss: 0.4640 - val_accuracy: 0.7793 - val_loss: 0.4912\n",
      "Epoch 32/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 733us/step - accuracy: 0.7732 - loss: 0.4685 - val_accuracy: 0.7701 - val_loss: 0.5416\n",
      "Epoch 33/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 704us/step - accuracy: 0.7770 - loss: 0.4628 - val_accuracy: 0.7241 - val_loss: 0.5582\n",
      "Epoch 34/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 734us/step - accuracy: 0.7778 - loss: 0.4614 - val_accuracy: 0.7190 - val_loss: 0.5725\n",
      "Epoch 35/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 699us/step - accuracy: 0.7758 - loss: 0.4609 - val_accuracy: 0.7997 - val_loss: 0.5073\n",
      "Epoch 36/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 724us/step - accuracy: 0.7733 - loss: 0.4627 - val_accuracy: 0.7597 - val_loss: 0.5368\n",
      "Epoch 37/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 706us/step - accuracy: 0.7767 - loss: 0.4589 - val_accuracy: 0.7161 - val_loss: 0.6092\n",
      "Epoch 38/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 726us/step - accuracy: 0.7776 - loss: 0.4591 - val_accuracy: 0.7609 - val_loss: 0.5542\n",
      "Epoch 39/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 732us/step - accuracy: 0.7776 - loss: 0.4590 - val_accuracy: 0.7912 - val_loss: 0.5096\n",
      "Epoch 40/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 697us/step - accuracy: 0.7762 - loss: 0.4581 - val_accuracy: 0.8027 - val_loss: 0.4595\n",
      "Epoch 41/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 727us/step - accuracy: 0.7810 - loss: 0.4547 - val_accuracy: 0.7865 - val_loss: 0.5169\n",
      "Epoch 42/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 708us/step - accuracy: 0.7775 - loss: 0.4582 - val_accuracy: 0.7812 - val_loss: 0.5058\n",
      "Epoch 43/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 738us/step - accuracy: 0.7804 - loss: 0.4545 - val_accuracy: 0.7858 - val_loss: 0.5018\n",
      "Epoch 44/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 705us/step - accuracy: 0.7820 - loss: 0.4497 - val_accuracy: 0.7777 - val_loss: 0.5261\n",
      "Epoch 45/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 725us/step - accuracy: 0.7820 - loss: 0.4500 - val_accuracy: 0.7945 - val_loss: 0.5095\n",
      "Epoch 46/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 714us/step - accuracy: 0.7835 - loss: 0.4463 - val_accuracy: 0.7542 - val_loss: 0.5615\n",
      "Epoch 47/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 729us/step - accuracy: 0.7833 - loss: 0.4481 - val_accuracy: 0.7742 - val_loss: 0.5322\n",
      "Epoch 48/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 714us/step - accuracy: 0.7841 - loss: 0.4469 - val_accuracy: 0.7978 - val_loss: 0.4715\n",
      "Epoch 49/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 736us/step - accuracy: 0.7866 - loss: 0.4438 - val_accuracy: 0.7954 - val_loss: 0.4884\n",
      "Epoch 50/50\n",
      "\u001b[1m2577/2577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 737us/step - accuracy: 0.7848 - loss: 0.4453 - val_accuracy: 0.7682 - val_loss: 0.5391\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step\n",
      "Accuracy for fold 4: 0.7681663837011885\n",
      "Training on fold 5...\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 758us/step - accuracy: 0.7340 - loss: 0.5518 - val_accuracy: 0.7448 - val_loss: 0.5508\n",
      "Epoch 2/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 738us/step - accuracy: 0.7468 - loss: 0.5247 - val_accuracy: 0.7256 - val_loss: 0.6041\n",
      "Epoch 3/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 709us/step - accuracy: 0.7517 - loss: 0.5167 - val_accuracy: 0.7741 - val_loss: 0.5451\n",
      "Epoch 4/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 747us/step - accuracy: 0.7511 - loss: 0.5153 - val_accuracy: 0.7201 - val_loss: 0.5927\n",
      "Epoch 5/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 714us/step - accuracy: 0.7543 - loss: 0.5092 - val_accuracy: 0.7890 - val_loss: 0.4863\n",
      "Epoch 6/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 739us/step - accuracy: 0.7511 - loss: 0.5116 - val_accuracy: 0.7872 - val_loss: 0.5068\n",
      "Epoch 7/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 724us/step - accuracy: 0.7531 - loss: 0.5051 - val_accuracy: 0.7469 - val_loss: 0.5578\n",
      "Epoch 8/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 743us/step - accuracy: 0.7559 - loss: 0.5052 - val_accuracy: 0.7902 - val_loss: 0.5005\n",
      "Epoch 9/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 715us/step - accuracy: 0.7558 - loss: 0.5019 - val_accuracy: 0.7669 - val_loss: 0.5504\n",
      "Epoch 10/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 739us/step - accuracy: 0.7572 - loss: 0.4985 - val_accuracy: 0.7919 - val_loss: 0.4688\n",
      "Epoch 11/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 728us/step - accuracy: 0.7568 - loss: 0.4986 - val_accuracy: 0.6930 - val_loss: 0.6020\n",
      "Epoch 12/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 747us/step - accuracy: 0.7609 - loss: 0.4935 - val_accuracy: 0.8043 - val_loss: 0.4766\n",
      "Epoch 13/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 730us/step - accuracy: 0.7568 - loss: 0.4973 - val_accuracy: 0.7918 - val_loss: 0.5199\n",
      "Epoch 14/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 741us/step - accuracy: 0.7587 - loss: 0.4926 - val_accuracy: 0.7851 - val_loss: 0.5143\n",
      "Epoch 15/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 722us/step - accuracy: 0.7625 - loss: 0.4893 - val_accuracy: 0.7650 - val_loss: 0.5260\n",
      "Epoch 16/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 751us/step - accuracy: 0.7629 - loss: 0.4869 - val_accuracy: 0.7880 - val_loss: 0.5160\n",
      "Epoch 17/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 723us/step - accuracy: 0.7642 - loss: 0.4858 - val_accuracy: 0.8011 - val_loss: 0.4894\n",
      "Epoch 18/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 748us/step - accuracy: 0.7640 - loss: 0.4849 - val_accuracy: 0.7868 - val_loss: 0.4758\n",
      "Epoch 19/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 724us/step - accuracy: 0.7648 - loss: 0.4828 - val_accuracy: 0.7899 - val_loss: 0.5241\n",
      "Epoch 20/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 743us/step - accuracy: 0.7650 - loss: 0.4839 - val_accuracy: 0.7786 - val_loss: 0.5313\n",
      "Epoch 21/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 722us/step - accuracy: 0.7660 - loss: 0.4812 - val_accuracy: 0.8019 - val_loss: 0.4715\n",
      "Epoch 22/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 749us/step - accuracy: 0.7621 - loss: 0.4833 - val_accuracy: 0.7704 - val_loss: 0.5820\n",
      "Epoch 23/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 723us/step - accuracy: 0.7655 - loss: 0.4806 - val_accuracy: 0.8066 - val_loss: 0.5258\n",
      "Epoch 24/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 748us/step - accuracy: 0.7660 - loss: 0.4785 - val_accuracy: 0.7956 - val_loss: 0.5004\n",
      "Epoch 25/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 716us/step - accuracy: 0.7683 - loss: 0.4777 - val_accuracy: 0.7975 - val_loss: 0.5111\n",
      "Epoch 26/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 748us/step - accuracy: 0.7686 - loss: 0.4746 - val_accuracy: 0.7850 - val_loss: 0.5069\n",
      "Epoch 27/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 722us/step - accuracy: 0.7664 - loss: 0.4756 - val_accuracy: 0.8010 - val_loss: 0.4498\n",
      "Epoch 28/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 748us/step - accuracy: 0.7735 - loss: 0.4697 - val_accuracy: 0.7644 - val_loss: 0.5162\n",
      "Epoch 29/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 722us/step - accuracy: 0.7720 - loss: 0.4688 - val_accuracy: 0.7887 - val_loss: 0.5031\n",
      "Epoch 30/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 749us/step - accuracy: 0.7735 - loss: 0.4686 - val_accuracy: 0.8066 - val_loss: 0.4589\n",
      "Epoch 31/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 722us/step - accuracy: 0.7740 - loss: 0.4681 - val_accuracy: 0.7853 - val_loss: 0.5413\n",
      "Epoch 32/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 751us/step - accuracy: 0.7711 - loss: 0.4682 - val_accuracy: 0.7370 - val_loss: 0.6019\n",
      "Epoch 33/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 725us/step - accuracy: 0.7751 - loss: 0.4636 - val_accuracy: 0.7830 - val_loss: 0.5252\n",
      "Epoch 34/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 747us/step - accuracy: 0.7773 - loss: 0.4635 - val_accuracy: 0.7944 - val_loss: 0.5035\n",
      "Epoch 35/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 742us/step - accuracy: 0.7758 - loss: 0.4605 - val_accuracy: 0.8093 - val_loss: 0.4768\n",
      "Epoch 36/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 721us/step - accuracy: 0.7750 - loss: 0.4635 - val_accuracy: 0.6737 - val_loss: 0.6581\n",
      "Epoch 37/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 742us/step - accuracy: 0.7768 - loss: 0.4593 - val_accuracy: 0.7855 - val_loss: 0.5240\n",
      "Epoch 38/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 721us/step - accuracy: 0.7783 - loss: 0.4595 - val_accuracy: 0.8038 - val_loss: 0.4927\n",
      "Epoch 39/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 751us/step - accuracy: 0.7796 - loss: 0.4568 - val_accuracy: 0.8008 - val_loss: 0.5100\n",
      "Epoch 40/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 721us/step - accuracy: 0.7787 - loss: 0.4565 - val_accuracy: 0.7796 - val_loss: 0.5225\n",
      "Epoch 41/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 743us/step - accuracy: 0.7799 - loss: 0.4526 - val_accuracy: 0.8065 - val_loss: 0.4588\n",
      "Epoch 42/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 725us/step - accuracy: 0.7818 - loss: 0.4514 - val_accuracy: 0.7798 - val_loss: 0.5155\n",
      "Epoch 43/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 750us/step - accuracy: 0.7820 - loss: 0.4520 - val_accuracy: 0.7411 - val_loss: 0.5688\n",
      "Epoch 44/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 744us/step - accuracy: 0.7828 - loss: 0.4515 - val_accuracy: 0.8093 - val_loss: 0.4867\n",
      "Epoch 45/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 725us/step - accuracy: 0.7836 - loss: 0.4491 - val_accuracy: 0.8019 - val_loss: 0.4844\n",
      "Epoch 46/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 746us/step - accuracy: 0.7815 - loss: 0.4494 - val_accuracy: 0.7936 - val_loss: 0.5424\n",
      "Epoch 47/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 716us/step - accuracy: 0.7812 - loss: 0.4491 - val_accuracy: 0.7513 - val_loss: 0.5693\n",
      "Epoch 48/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 751us/step - accuracy: 0.7850 - loss: 0.4447 - val_accuracy: 0.7966 - val_loss: 0.4916\n",
      "Epoch 49/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 717us/step - accuracy: 0.7841 - loss: 0.4449 - val_accuracy: 0.7984 - val_loss: 0.5224\n",
      "Epoch 50/50\n",
      "\u001b[1m2580/2580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 745us/step - accuracy: 0.7866 - loss: 0.4426 - val_accuracy: 0.7885 - val_loss: 0.4890\n",
      "\u001b[1m369/369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step\n",
      "Accuracy for fold 5: 0.7885398981324279\n",
      "\n",
      "Final Report:\n",
      "Mean Accuracy: 0.7516524881290685\n",
      "Standard Deviation of Accuracy: 0.04301483436116115\n",
      "\n",
      "Classification Report for fold 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.81      0.87     10327\n",
      "         1.0       0.32      0.64      0.43      1453\n",
      "\n",
      "    accuracy                           0.79     11780\n",
      "   macro avg       0.63      0.73      0.65     11780\n",
      "weighted avg       0.87      0.79      0.82     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.81      0.87     10327\n",
      "         1.0       0.32      0.64      0.43      1453\n",
      "\n",
      "    accuracy                           0.79     11780\n",
      "   macro avg       0.63      0.73      0.65     11780\n",
      "weighted avg       0.87      0.79      0.82     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.81      0.87     10327\n",
      "         1.0       0.32      0.64      0.43      1453\n",
      "\n",
      "    accuracy                           0.79     11780\n",
      "   macro avg       0.63      0.73      0.65     11780\n",
      "weighted avg       0.87      0.79      0.82     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.81      0.87     10327\n",
      "         1.0       0.32      0.64      0.43      1453\n",
      "\n",
      "    accuracy                           0.79     11780\n",
      "   macro avg       0.63      0.73      0.65     11780\n",
      "weighted avg       0.87      0.79      0.82     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.81      0.87     10327\n",
      "         1.0       0.32      0.64      0.43      1453\n",
      "\n",
      "    accuracy                           0.79     11780\n",
      "   macro avg       0.63      0.73      0.65     11780\n",
      "weighted avg       0.87      0.79      0.82     11780\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_smote_deep_learning_kfold(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_smote_passive_aggressive_kfold\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "def train_smote_passive_aggressive_kfold(processed_data, k=5):\n",
    "    df = processed_data.copy()\n",
    "    warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "    \n",
    "    X = df.drop('Status', axis=1)\n",
    "    y = df['Status']\n",
    "\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    accuracies = []\n",
    "    reports = []\n",
    "\n",
    "    fold = 1\n",
    "    for train_index, test_index in tqdm(kf.split(X), total=k, desc=\"K-Fold Progress\"):\n",
    "        print(f\"Training on fold {fold}...\")\n",
    "        \n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Áp dụng SMOTE cho tập train\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_res, y_train_res = smote.fit_resample(X_train, y_train)        \n",
    "\n",
    "        # Khởi tạo và huấn luyện mô hình PassiveAggressiveClassifier trên tập train\n",
    "        model = PassiveAggressiveClassifier()\n",
    "        model.fit(X_train_res, y_train_res)\n",
    "        \n",
    "        # Dự đoán trên tập test\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Đánh giá mô hình\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "        reports.append(report)\n",
    "\n",
    "        print(f\"Accuracy for fold {fold}: {accuracy}\")\n",
    "        fold += 1\n",
    "\n",
    "    print(\"\\nFinal Report:\")\n",
    "    print(f\"Mean Accuracy: {np.mean(accuracies)}\")\n",
    "    print(f\"Standard Deviation of Accuracy: {np.std(accuracies)}\")\n",
    "    \n",
    "    for i, report in enumerate(reports):\n",
    "        print(f\"\\nClassification Report for fold {i+1}:\")\n",
    "        print(classification_report(y.iloc[test_index], y_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K-Fold Progress:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K-Fold Progress:  20%|██        | 1/5 [00:00<00:03,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for fold 1: 0.28036669213139803\n",
      "Training on fold 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K-Fold Progress:  40%|████      | 2/5 [00:01<00:02,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for fold 2: 0.2688455008488964\n",
      "Training on fold 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K-Fold Progress:  60%|██████    | 3/5 [00:02<00:01,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for fold 3: 0.7193548387096774\n",
      "Training on fold 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K-Fold Progress:  80%|████████  | 4/5 [00:03<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for fold 4: 0.33251273344651955\n",
      "Training on fold 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K-Fold Progress: 100%|██████████| 5/5 [00:04<00:00,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for fold 5: 0.3574702886247878\n",
      "\n",
      "Final Report:\n",
      "Mean Accuracy: 0.39171001075225587\n",
      "Standard Deviation of Accuracy: 0.16704540214823357\n",
      "\n",
      "Classification Report for fold 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.29      0.44     10327\n",
      "         1.0       0.15      0.87      0.25      1453\n",
      "\n",
      "    accuracy                           0.36     11780\n",
      "   macro avg       0.54      0.58      0.34     11780\n",
      "weighted avg       0.84      0.36      0.41     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.29      0.44     10327\n",
      "         1.0       0.15      0.87      0.25      1453\n",
      "\n",
      "    accuracy                           0.36     11780\n",
      "   macro avg       0.54      0.58      0.34     11780\n",
      "weighted avg       0.84      0.36      0.41     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.29      0.44     10327\n",
      "         1.0       0.15      0.87      0.25      1453\n",
      "\n",
      "    accuracy                           0.36     11780\n",
      "   macro avg       0.54      0.58      0.34     11780\n",
      "weighted avg       0.84      0.36      0.41     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.29      0.44     10327\n",
      "         1.0       0.15      0.87      0.25      1453\n",
      "\n",
      "    accuracy                           0.36     11780\n",
      "   macro avg       0.54      0.58      0.34     11780\n",
      "weighted avg       0.84      0.36      0.41     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.29      0.44     10327\n",
      "         1.0       0.15      0.87      0.25      1453\n",
      "\n",
      "    accuracy                           0.36     11780\n",
      "   macro avg       0.54      0.58      0.34     11780\n",
      "weighted avg       0.84      0.36      0.41     11780\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_smote_passive_aggressive_kfold(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_smote_ridge_classifier_kfold\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "def train_smote_ridge_classifier_kfold(processed_data, k=5):\n",
    "    df = processed_data.copy()\n",
    "    warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "    \n",
    "    X = df.drop('Status', axis=1)\n",
    "    y = df['Status']\n",
    "\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    accuracies = []\n",
    "    reports = []\n",
    "\n",
    "    fold = 1\n",
    "    for train_index, test_index in tqdm(kf.split(X), total=k, desc=\"K-Fold Progress\"):\n",
    "        print(f\"Training on fold {fold}...\")\n",
    "        \n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Áp dụng SMOTE cho tập train\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "        \n",
    "        # Khởi tạo và huấn luyện mô hình RidgeClassifier trên tập train đã áp dụng SMOTE\n",
    "        model = RidgeClassifier()\n",
    "        model.fit(X_train_res, y_train_res)\n",
    "        \n",
    "        # Dự đoán trên tập test\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Đánh giá mô hình\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "        reports.append(report)\n",
    "\n",
    "        print(f\"Accuracy for fold {fold}: {accuracy}\")\n",
    "        fold += 1\n",
    "\n",
    "    print(\"\\nFinal Report:\")\n",
    "    print(f\"Mean Accuracy: {np.mean(accuracies)}\")\n",
    "    print(f\"Standard Deviation of Accuracy: {np.std(accuracies)}\")\n",
    "    \n",
    "    for i, report in enumerate(reports):\n",
    "        print(f\"\\nClassification Report for fold {i+1}:\")\n",
    "        print(classification_report(y.iloc[test_index], y_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K-Fold Progress:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K-Fold Progress:  20%|██        | 1/5 [00:00<00:01,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for fold 1: 0.8281979458450047\n",
      "Training on fold 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K-Fold Progress:  40%|████      | 2/5 [00:00<00:01,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for fold 2: 0.8221561969439728\n",
      "Training on fold 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K-Fold Progress:  60%|██████    | 3/5 [00:01<00:00,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for fold 3: 0.8178268251273345\n",
      "Training on fold 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K-Fold Progress:  80%|████████  | 4/5 [00:01<00:00,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for fold 4: 0.8228353140916809\n",
      "Training on fold 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K-Fold Progress: 100%|██████████| 5/5 [00:02<00:00,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for fold 5: 0.8210526315789474\n",
      "\n",
      "Final Report:\n",
      "Mean Accuracy: 0.8224137827173881\n",
      "Standard Deviation of Accuracy: 0.0033643274089091733\n",
      "\n",
      "Classification Report for fold 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.85      0.89     10327\n",
      "         1.0       0.37      0.63      0.46      1453\n",
      "\n",
      "    accuracy                           0.82     11780\n",
      "   macro avg       0.65      0.74      0.68     11780\n",
      "weighted avg       0.87      0.82      0.84     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.85      0.89     10327\n",
      "         1.0       0.37      0.63      0.46      1453\n",
      "\n",
      "    accuracy                           0.82     11780\n",
      "   macro avg       0.65      0.74      0.68     11780\n",
      "weighted avg       0.87      0.82      0.84     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.85      0.89     10327\n",
      "         1.0       0.37      0.63      0.46      1453\n",
      "\n",
      "    accuracy                           0.82     11780\n",
      "   macro avg       0.65      0.74      0.68     11780\n",
      "weighted avg       0.87      0.82      0.84     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.85      0.89     10327\n",
      "         1.0       0.37      0.63      0.46      1453\n",
      "\n",
      "    accuracy                           0.82     11780\n",
      "   macro avg       0.65      0.74      0.68     11780\n",
      "weighted avg       0.87      0.82      0.84     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.85      0.89     10327\n",
      "         1.0       0.37      0.63      0.46      1453\n",
      "\n",
      "    accuracy                           0.82     11780\n",
      "   macro avg       0.65      0.74      0.68     11780\n",
      "weighted avg       0.87      0.82      0.84     11780\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_smote_ridge_classifier_kfold(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_smote_random_forest_class_weight_kfold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "def train_smote_random_forest_class_weight_kfold(processed_data, k=5):\n",
    "    df = processed_data.copy()\n",
    "    warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "    \n",
    "    X = df.drop('Status', axis=1)\n",
    "    y = df['Status']\n",
    "\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    accuracies = []\n",
    "    reports = []\n",
    "\n",
    "    fold = 1\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        print(f\"Training on fold {fold}...\")\n",
    "        \n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # Áp dụng SMOTE cho tập train\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "        \n",
    "        # Khởi tạo và huấn luyện mô hình RandomForestClassifier trên tập train đã được resample\n",
    "        model = RandomForestClassifier(class_weight='balanced',random_state=42)\n",
    "        model.fit(X_train_res, y_train_res)\n",
    "        \n",
    "        # Dự đoán trên tập test\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Đánh giá mô hình\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "        reports.append(report)\n",
    "\n",
    "        print(f\"Accuracy for fold {fold}: {accuracy}\")\n",
    "        fold += 1\n",
    "\n",
    "    # Tính toán và in ra báo cáo cuối cùng\n",
    "    print(\"\\nFinal Report:\")\n",
    "    print(f\"Mean Accuracy: {np.mean(accuracies)}\")\n",
    "    print(f\"Standard Deviation of Accuracy: {np.std(accuracies)}\")\n",
    "    \n",
    "    # In ra classification report cho từng fold\n",
    "    for i, report in enumerate(reports):\n",
    "        print(f\"\\nClassification Report for fold {i+1}:\")\n",
    "        print(classification_report(y.iloc[test_index], y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 1...\n",
      "Accuracy for fold 1: 0.8695356930651048\n",
      "Training on fold 2...\n",
      "Accuracy for fold 2: 0.8679966044142614\n",
      "Training on fold 3...\n",
      "Accuracy for fold 3: 0.8673174872665534\n",
      "Training on fold 4...\n",
      "Accuracy for fold 4: 0.8735993208828523\n",
      "Training on fold 5...\n",
      "Accuracy for fold 5: 0.86893039049236\n",
      "\n",
      "Final Report:\n",
      "Mean Accuracy: 0.8694758992242264\n",
      "Standard Deviation of Accuracy: 0.0021977632524268695\n",
      "\n",
      "Classification Report for fold 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.94      0.93     10327\n",
      "         1.0       0.46      0.37      0.41      1453\n",
      "\n",
      "    accuracy                           0.87     11780\n",
      "   macro avg       0.69      0.65      0.67     11780\n",
      "weighted avg       0.86      0.87      0.86     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.94      0.93     10327\n",
      "         1.0       0.46      0.37      0.41      1453\n",
      "\n",
      "    accuracy                           0.87     11780\n",
      "   macro avg       0.69      0.65      0.67     11780\n",
      "weighted avg       0.86      0.87      0.86     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.94      0.93     10327\n",
      "         1.0       0.46      0.37      0.41      1453\n",
      "\n",
      "    accuracy                           0.87     11780\n",
      "   macro avg       0.69      0.65      0.67     11780\n",
      "weighted avg       0.86      0.87      0.86     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.94      0.93     10327\n",
      "         1.0       0.46      0.37      0.41      1453\n",
      "\n",
      "    accuracy                           0.87     11780\n",
      "   macro avg       0.69      0.65      0.67     11780\n",
      "weighted avg       0.86      0.87      0.86     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.94      0.93     10327\n",
      "         1.0       0.46      0.37      0.41      1453\n",
      "\n",
      "    accuracy                           0.87     11780\n",
      "   macro avg       0.69      0.65      0.67     11780\n",
      "weighted avg       0.86      0.87      0.86     11780\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_smote_random_forest_class_weight_kfold (processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_bayesian_glm_kfold\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "def train_bayesian_glm_kfold(processed_data, k=5):\n",
    "    df = processed_data.copy()\n",
    "    warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "    \n",
    "    X = df.drop('Status', axis=1)\n",
    "    y = df['Status']\n",
    "\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    accuracies = []\n",
    "    reports = []\n",
    "\n",
    "    fold = 1\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        print(f\"Training on fold {fold}...\")\n",
    "        \n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Khởi tạo và huấn luyện mô hình Bayesian GLM (BayesianRidge) trên tập train\n",
    "        model = BayesianRidge()\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Dự đoán trên tập test\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred = (y_pred > 0.5).astype(int)  # Chuyển đổi thành nhãn nhị phân\n",
    "        \n",
    "        # Đánh giá mô hình\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "        reports.append(report)\n",
    "\n",
    "        print(f\"Accuracy for fold {fold}: {accuracy}\")\n",
    "        fold += 1\n",
    "\n",
    "    print(\"\\nFinal Report:\")\n",
    "    print(f\"Mean Accuracy: {np.mean(accuracies)}\")\n",
    "    print(f\"Standard Deviation of Accuracy: {np.std(accuracies)}\")\n",
    "    \n",
    "    for i, report in enumerate(reports):\n",
    "        print(f\"\\nClassification Report for fold {i+1}:\")\n",
    "        print(classification_report(y.iloc[test_index], y_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 1...\n",
      "Accuracy for fold 1: 0.8755623461505815\n",
      "Training on fold 2...\n",
      "Accuracy for fold 2: 0.8741086587436333\n",
      "Training on fold 3...\n",
      "Accuracy for fold 3: 0.8739388794567062\n",
      "Training on fold 4...\n",
      "Accuracy for fold 4: 0.8800509337860781\n",
      "Training on fold 5...\n",
      "Accuracy for fold 5: 0.8767402376910017\n",
      "\n",
      "Final Report:\n",
      "Mean Accuracy: 0.8760802111656002\n",
      "Standard Deviation of Accuracy: 0.002233507454962591\n",
      "\n",
      "Classification Report for fold 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      1.00      0.93     10327\n",
      "         1.0       1.00      0.00      0.00      1453\n",
      "\n",
      "    accuracy                           0.88     11780\n",
      "   macro avg       0.94      0.50      0.47     11780\n",
      "weighted avg       0.89      0.88      0.82     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      1.00      0.93     10327\n",
      "         1.0       1.00      0.00      0.00      1453\n",
      "\n",
      "    accuracy                           0.88     11780\n",
      "   macro avg       0.94      0.50      0.47     11780\n",
      "weighted avg       0.89      0.88      0.82     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      1.00      0.93     10327\n",
      "         1.0       1.00      0.00      0.00      1453\n",
      "\n",
      "    accuracy                           0.88     11780\n",
      "   macro avg       0.94      0.50      0.47     11780\n",
      "weighted avg       0.89      0.88      0.82     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      1.00      0.93     10327\n",
      "         1.0       1.00      0.00      0.00      1453\n",
      "\n",
      "    accuracy                           0.88     11780\n",
      "   macro avg       0.94      0.50      0.47     11780\n",
      "weighted avg       0.89      0.88      0.82     11780\n",
      "\n",
      "\n",
      "Classification Report for fold 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      1.00      0.93     10327\n",
      "         1.0       1.00      0.00      0.00      1453\n",
      "\n",
      "    accuracy                           0.88     11780\n",
      "   macro avg       0.94      0.50      0.47     11780\n",
      "weighted avg       0.89      0.88      0.82     11780\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_bayesian_glm_kfold (processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_svm_kfold\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def train_svm_kfold(processed_data, k=5):\n",
    "    df = processed_data.copy()\n",
    "    warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "    \n",
    "    X = df.drop('Status', axis=1)\n",
    "    y = df['Status']\n",
    "\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    accuracies = []\n",
    "    reports = []\n",
    "\n",
    "    fold = 1\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        print(f\"Training on fold {fold}...\")\n",
    "        \n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Khởi tạo và huấn luyện mô hình SVM trên tập train\n",
    "        model = SVC(probability=True)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Dự đoán trên tập test\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Đánh giá mô hình\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "        reports.append(report)\n",
    "\n",
    "        print(f\"Accuracy for fold {fold}: {accuracy}\")\n",
    "        fold += 1\n",
    "\n",
    "    print(\"\\nFinal Report:\")\n",
    "    print(f\"Mean Accuracy: {np.mean(accuracies)}\")\n",
    "    print(f\"Standard Deviation of Accuracy: {np.std(accuracies)}\")\n",
    "    \n",
    "    for i, report in enumerate(reports):\n",
    "        print(f\"\\nClassification Report for fold {i+1}:\")\n",
    "        print(classification_report(y.iloc[test_index], y_pred, zero_division=0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_svm_kfold(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_automl_kfold with tpot\n",
    "from tpot import TPOTClassifier\n",
    "\n",
    "def train_automl_kfold(processed_data, k=5, generations=50, population_size=50):\n",
    "    df = processed_data.copy()\n",
    "    warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "    \n",
    "    X = df.drop('Status', axis=1)\n",
    "    y = df['Status']\n",
    "\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    accuracies = []\n",
    "    reports = []\n",
    "\n",
    "    fold = 1\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        print(f\"Training on fold {fold}...\")\n",
    "        \n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Khởi tạo và huấn luyện mô hình TPOTClassifier trên tập train\n",
    "        model = TPOTClassifier(generations=generations, population_size=population_size, verbosity=2, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Dự đoán trên tập test\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Đánh giá mô hình\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "        reports.append(report)\n",
    "\n",
    "        print(f\"Accuracy for fold {fold}: {accuracy}\")\n",
    "        fold += 1\n",
    "\n",
    "    # Tính toán và in ra báo cáo cuối cùng\n",
    "    print(\"\\nFinal Report:\")\n",
    "    print(f\"Mean Accuracy: {np.mean(accuracies)}\")\n",
    "    print(f\"Standard Deviation of Accuracy: {np.std(accuracies)}\")\n",
    "    \n",
    "    # In ra classification report cho từng fold\n",
    "    for i, report in enumerate(reports):\n",
    "        print(f\"\\nClassification Report for fold {i+1}:\")\n",
    "        print(classification_report(y.iloc[test_index], y_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_automl_kfold(processed_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
